#!/usr/bin/env python3
"""
ç•ªèŒ„å°è¯´ä¸‹è½½å™¨æ ¸å¿ƒæ¨¡å—
"""

import time
import requests
import bs4
import re
import os
import random
import json
import urllib3
import threading
import signal
import sys
import stem
from stem import Signal
from stem.control import Controller
from concurrent.futures import ThreadPoolExecutor, as_completed
from tqdm import tqdm
from collections import OrderedDict
from fake_useragent import UserAgent
from typing import Optional, Dict
from Crypto.Cipher import AES
from Crypto.Util.Padding import pad, unpad
from Crypto.Random import get_random_bytes
import base64
import gzip
from urllib.parse import urlencode, quote

# å¯¼å…¥ç« èŠ‚çŸ«æ­£æ¨¡å—
try:
    from chapter_corrector import correct_chapters, analyze_chapter_title
    CHAPTER_CORRECTION_AVAILABLE = True
except ImportError:
    print("è­¦å‘Š: ç« èŠ‚çŸ«æ­£æ¨¡å—æœªæ‰¾åˆ°ï¼Œå°†è·³è¿‡ç« èŠ‚çŸ«æ­£åŠŸèƒ½")
    CHAPTER_CORRECTION_AVAILABLE = False

# ç¦ç”¨SSLè¯ä¹¦éªŒè¯è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
requests.packages.urllib3.disable_warnings()

# æ·»åŠ Toré…ç½®
TOR_CONFIG = {
    "enabled": False,
    "proxy_port": 9050,
    "max_retries": 3,
    "change_ip_after": 980,
    "request_timeout": 35
}

# åˆå§‹åŒ–è¯·æ±‚è®¡æ•°å™¨
request_counter = 0

def get_tor_session():
    """åˆ›å»ºæ–°çš„Torä¼šè¯"""
    session = requests.session()
    session.proxies = {
        'http': f'socks5h://127.0.0.1:{TOR_CONFIG["proxy_port"]}',
        'https': f'socks5h://127.0.0.1:{TOR_CONFIG["proxy_port"]}'
    }
    return session

def renew_tor_ip():
    """é‡å»ºä¼šè¯"""
    if not TOR_CONFIG["enabled"]:
        return

    print("æ­£åœ¨é‡å»ºTorä¼šè¯æ›´æ¢IP...")
    global request_counter
    request_counter = 0
    time.sleep(5)
    print("IPæ›´æ¢å®Œæˆ")

def check_tor_connection():
    """æ£€æŸ¥Torè¿æ¥æ˜¯å¦æ­£å¸¸"""
    try:
        session = get_tor_session()
        response = session.get(
            "https://check.torproject.org/",
            timeout=TOR_CONFIG["request_timeout"]
        )
        if "Congratulations" in response.text:
            print("Torè¿æ¥æˆåŠŸ!")
            return True
    except Exception as e:
        print(f"Torè¿æ¥æ£€æŸ¥å¤±è´¥: {str(e)}")
    return False

def enable_tor_support():
    """å¯ç”¨Toræ”¯æŒ"""
    TOR_CONFIG["enabled"] = True
    print("æ­£åœ¨å¯ç”¨Toræ”¯æŒ...")
    if check_tor_connection():
        print("Toræ”¯æŒå·²å¯ç”¨!")
        return True
    else:
        print("æ— æ³•è¿æ¥åˆ°Torç½‘ç»œï¼Œè¯·ç¡®ä¿ToræœåŠ¡æ­£åœ¨è¿è¡Œï¼Œå°†ä½¿ç”¨å…¶ä»–ä¸‹è½½æ¸ é“è¿›è¡Œä¸‹è½½\n")
        TOR_CONFIG["enabled"] = False
        return False

def make_request(url, headers=None, params=None, data=None, method='GET', verify=False, use_tor=False, timeout=None):
    """é€šç”¨çš„è¯·æ±‚å‡½æ•°"""
    global request_counter

    if headers is None:
        headers = get_headers()

    session = None
    if use_tor and TOR_CONFIG["enabled"]:
        session = get_tor_session()
        # è®¡æ•°å™¨é€»è¾‘
        request_counter += 1
        if request_counter % TOR_CONFIG["change_ip_after"] == 0:
            renew_tor_ip()
    else:
        session = requests.Session()

    try:
        request_params = {
            'headers': headers,
            'params': params,
            'verify': verify,
            'timeout': timeout if timeout is not None else TOR_CONFIG["request_timeout"]
        }

        if data:
            request_params['data'] = data

        if method.upper() == 'GET':
            response = session.get(url, **request_params)
        elif method.upper() == 'POST':
            response = session.post(url, **request_params)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„HTTPæ–¹æ³•: {method}")

        return response
    except Exception as e:
        print(f"è¯·æ±‚å¤±è´¥: {str(e)}")
        if use_tor and TOR_CONFIG["enabled"]:
            renew_tor_ip()
            return make_request(url, headers, params, data, method, verify, use_tor, timeout)
        raise

# å…¨å±€é…ç½®
CONFIG = {
    "max_workers": 4,
    "max_retries": 3,
    "request_timeout": 15,
    "status_file": "chapter.json",
    "request_rate_limit": 0.4,
    "auth_token": "wcnmd91jb",
    "server_url": "https://dlbkltos.s7123.xyz:5080/api/sources",
    "api_endpoints": [],
    "batch_config": {
        "name": "qyuing",
        "base_url": None,
        "batch_endpoint": None,
        "token": None,
        "max_batch_size": 290,
        "timeout": 10,
        "enabled": True
    }
}

def get_headers() -> Dict[str, str]:
    """ç”Ÿæˆéšæœºè¯·æ±‚å¤´"""
    # é¢„å®šä¹‰çš„ç”¨æˆ·ä»£ç†åˆ—è¡¨ï¼Œé¿å…ä¾èµ–fake_useragentçš„ç½‘ç»œè¯·æ±‚
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/119.0",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Edge/121.0.0.0 Safari/537.36",
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36"
    ]

    try:
        # å°è¯•ä½¿ç”¨fake_useragent
        browsers = ['chrome', 'edge']
        browser = random.choice(browsers)

        if browser == 'chrome':
            user_agent = UserAgent().chrome
        else:
            user_agent = UserAgent().edge
    except Exception:
        # å¦‚æœfake_useragentå¤±è´¥ï¼Œä½¿ç”¨é¢„å®šä¹‰çš„ç”¨æˆ·ä»£ç†
        user_agent = random.choice(user_agents)

    return {
        "User-Agent": user_agent,
        "Accept": "application/json, text/javascript, */*; q=0.01",
        "Accept-Language": "zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7",
        "Referer": "https://fanqienovel.com/",
        "X-Requested-With": "XMLHttpRequest",
    }

def search_novels(query: str, page: int = 0, limit: int = 20) -> Optional[Dict]:
    """
    æœç´¢ç•ªèŒ„å°è¯´
    
    Args:
        query: æœç´¢å…³é”®è¯
        page: é¡µç ï¼Œä»0å¼€å§‹
        limit: æ¯é¡µæ•°é‡é™åˆ¶
        
    Returns:
        æœç´¢ç»“æœå­—å…¸ï¼ŒåŒ…å«ä¹¦ç±åˆ—è¡¨ç­‰ä¿¡æ¯
    """
    try:
        url = "https://fq.66ds.de/api/search"
        
        params = {
            'query': query,
            'offset': page * limit,
            'limit': limit,
            'page': page,
            'aid': 1967,
            'isLoadMore': False
        }
        
        headers = {
            'Content-Type': 'application/json',
            'Referer': f'https://fq.66ds.de/search/index.html?q={quote(query)}',
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36 Edg/138.0.0.0',
            'Accept': 'application/json, text/javascript, */*; q=0.01',
            'Accept-Language': 'zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7',
        }
        
        response = requests.get(url, params=params, headers=headers, timeout=10)
        response.raise_for_status()
        
        return response.json()
        
    except Exception as e:
        print(f"æœç´¢å°è¯´æ—¶å‡ºé”™: {str(e)}")
        return None

def format_search_results(search_data: Dict) -> str:
    """
    æ ¼å¼åŒ–æœç´¢ç»“æœä¸ºå¯è¯»æ–‡æœ¬
    
    Args:
        search_data: æœç´¢APIè¿”å›çš„æ•°æ®
        
    Returns:
        æ ¼å¼åŒ–åçš„æœç´¢ç»“æœæ–‡æœ¬
    """
    if not search_data or search_data.get('code') != 0:
        return "æœç´¢å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åå†è¯•"
    
    book_data = search_data.get('data', {}).get('book_data', [])
    if not book_data:
        return "æœªæ‰¾åˆ°ç›¸å…³å°è¯´"
    
    result = f"æ‰¾åˆ° {len(book_data)} æœ¬ç›¸å…³å°è¯´ï¼š\n\n"
    
    for i, book in enumerate(book_data, 1):
        book_id = book.get('book_id', '')
        book_name = book.get('book_name', 'æœªçŸ¥')
        author = book.get('author', 'æœªçŸ¥ä½œè€…')
        read_count = book.get('read_count', '0')
        creation_status = "å®Œç»“" if book.get('creation_status') == "0" else "è¿è½½ä¸­"
        abstract = book.get('abstract', 'æ— ç®€ä»‹')[:100] + ('...' if len(book.get('abstract', '')) > 100 else '')
        
        # è·å–åˆ†ç±»æ ‡ç­¾
        categories = []
        for tag in book.get('category_tags', []):
            categories.append(tag.get('category_name', ''))
        category_text = ' | '.join(categories) if categories else 'æ— åˆ†ç±»'
        
        result += f"{i}. ã€Š{book_name}ã€‹\n"
        result += f"   ä½œè€…: {author}\n"
        result += f"   ID: {book_id}\n"
        result += f"   çŠ¶æ€: {creation_status}\n"
        result += f"   é˜…è¯»é‡: {read_count}\n"
        result += f"   åˆ†ç±»: {category_text}\n"
        result += f"   ç®€ä»‹: {abstract}\n"
        result += f"   {'='*50}\n\n"
    
    return result

def get_enhanced_book_info(book_id: str) -> Optional[Dict]:
    """
    é€šè¿‡å¤šä¸ªæ¥æºè·å–å¢å¼ºçš„ä¹¦ç±ä¿¡æ¯ï¼Œä¼˜å…ˆä½¿ç”¨æœ€å®Œæ•´çš„æ•°æ®
    
    Args:
        book_id: ä¹¦ç±ID
        
    Returns:
        åŒ…å«è¯¦ç»†ä¿¡æ¯çš„å­—å…¸
    """
    try:
        # åˆå§‹åŒ–ç»“æœå­—å…¸
        enhanced_info = {
            'book_id': book_id,
            'book_name': None,
            'author': None,
            'description': None,
            'thumb_url': None,
            'read_count': None,
            'creation_status': None,
            'category_tags': [],
            'genre': None,
            'book_type': None
        }
        
        # 1. å…ˆé€šè¿‡å¢å¼ºçš„get_book_infoè·å–å®Œæ•´ä¿¡æ¯
        try:
            headers = get_headers()
            book_info = get_book_info(book_id, headers)

            # ä½¿ç”¨å®˜ç½‘ä¿¡æ¯ä½œä¸ºåŸºç¡€
            if book_info:
                enhanced_info['book_name'] = book_info.get('name')
                enhanced_info['author'] = book_info.get('author')
                enhanced_info['description'] = book_info.get('description')
                enhanced_info['thumb_url'] = book_info.get('cover_url')
                enhanced_info['creation_status'] = book_info.get('status')
                enhanced_info['category_tags'] = book_info.get('tags', [])
                # æ·»åŠ é¢å¤–ä¿¡æ¯
                enhanced_info['word_count'] = book_info.get('word_count')
                enhanced_info['last_update'] = book_info.get('last_update')

        except Exception as e:
            print(f"è·å–åŸºæœ¬ä¹¦ç±ä¿¡æ¯å¤±è´¥: {str(e)}")
        
        # 2. é€šè¿‡æœç´¢APIè·å–è¯¦ç»†ä¿¡æ¯
        search_info = None
        if enhanced_info['book_name']:
            # å¦‚æœæœ‰ä¹¦åï¼Œç”¨ä¹¦åæœç´¢
            search_result = search_novels(enhanced_info['book_name'], limit=5)
            if search_result and search_result.get('code') == 0:
                book_data = search_result.get('data', {}).get('book_data', [])
                
                # æŸ¥æ‰¾åŒ¹é…çš„ä¹¦ç±ï¼ˆåªé€šè¿‡IDåŒ¹é…ï¼Œç¡®ä¿æ˜¯åŒä¸€æœ¬ä¹¦ï¼‰
                for book in book_data:
                    if book.get('book_id') == book_id:
                        search_info = book
                        break
                    # ç§»é™¤æŒ‰ä¹¦ååŒ¹é…ï¼Œå› ä¸ºå¯èƒ½åŒ¹é…åˆ°åŒåä½†ä¸åŒä½œè€…çš„ä¹¦
        
        # 3. å¦‚æœé€šè¿‡ä¹¦åæ²¡æ‰¾åˆ°ï¼Œå°è¯•é€šè¿‡ä½œè€…æœç´¢
        if not search_info and enhanced_info['author']:
            try:
                search_result = search_novels(enhanced_info['author'], limit=10)
                if search_result and search_result.get('code') == 0:
                    book_data = search_result.get('data', {}).get('book_data', [])
                    
                    # æŸ¥æ‰¾åŒ¹é…çš„ä¹¦ç±ï¼ˆåªé€šè¿‡IDåŒ¹é…ï¼‰
                    for book in book_data:
                        if book.get('book_id') == book_id:
                            search_info = book
                            break
            except Exception as e:
                print(f"é€šè¿‡ä½œè€…æœç´¢å¤±è´¥: {str(e)}")
        
        # 4. æ™ºèƒ½åˆå¹¶ä¿¡æ¯ï¼šä¼˜å…ˆä½¿ç”¨å®˜ç½‘ä¿¡æ¯ï¼Œæœç´¢APIä½œä¸ºè¡¥å……
        if search_info:
            # ä¹¦åï¼šä¼˜å…ˆä½¿ç”¨å®˜ç½‘ä¿¡æ¯ï¼Œå¦‚æœå®˜ç½‘æ²¡æœ‰æ‰ä½¿ç”¨æœç´¢ç»“æœ
            if not enhanced_info['book_name'] and search_info.get('book_name') and search_info['book_name'].strip():
                enhanced_info['book_name'] = search_info['book_name']

            # ä½œè€…ï¼šä¼˜å…ˆä½¿ç”¨å®˜ç½‘ä¿¡æ¯ï¼Œå¦‚æœå®˜ç½‘æ²¡æœ‰æ‰ä½¿ç”¨æœç´¢ç»“æœ
            if not enhanced_info['author'] and search_info.get('author') and search_info['author'].strip():
                enhanced_info['author'] = search_info['author']

            # ç®€ä»‹ï¼šåªæœ‰å½“ HTML è§£æä¸åˆ°æˆ–ç­‰äºé»˜è®¤æ—¶æ‰ç”¨ API æè¿°
            search_desc = search_info.get('abstract', '').strip()
            if (not enhanced_info['description'] or enhanced_info['description'] == 'æš‚æ— ç®€ä»‹') and search_desc:
                enhanced_info['description'] = search_desc
            
            # å°é¢ï¼šä¼˜å…ˆä½¿ç”¨å®˜ç½‘ä¿¡æ¯ï¼Œå¦‚æœå®˜ç½‘æ²¡æœ‰æ‰ä½¿ç”¨æœç´¢ç»“æœ
            if not enhanced_info['thumb_url'] and search_info.get('thumb_url'):
                enhanced_info['thumb_url'] = search_info['thumb_url']
            
            if search_info.get('read_count'):
                enhanced_info['read_count'] = search_info['read_count']
            
            if search_info.get('creation_status') is not None:
                enhanced_info['creation_status'] = search_info['creation_status']
            
            # åˆ†ç±»æ ‡ç­¾ï¼šåªæœ‰å½“ HTML æ²¡è§£æåˆ°ä»»ä½•æ ‡ç­¾æ—¶æ‰ç”¨ API
            if not enhanced_info['category_tags'] and search_info.get('category_tags'):
                enhanced_info['category_tags'] = search_info['category_tags']
            
            if search_info.get('genre') is not None:
                enhanced_info['genre'] = search_info['genre']
            
            if search_info.get('book_type') is not None:
                enhanced_info['book_type'] = search_info['book_type']
        
        # 5. æœ€ç»ˆæ•°æ®éªŒè¯å’Œæ¸…ç†
        # ç¡®ä¿åŸºæœ¬ä¿¡æ¯ä¸ä¸ºç©º
        if not enhanced_info['book_name'] or enhanced_info['book_name'].strip() == '':
            enhanced_info['book_name'] = f"æœªçŸ¥å°è¯´_{book_id}"
        
        if not enhanced_info['author'] or enhanced_info['author'].strip() == '':
            enhanced_info['author'] = "æœªçŸ¥ä½œè€…"
        
        if not enhanced_info['description'] or enhanced_info['description'].strip() == '':
            enhanced_info['description'] = "æš‚æ— ç®€ä»‹"
        
        # éªŒè¯åˆ†ç±»æ ‡ç­¾æ ¼å¼
        if enhanced_info['category_tags'] and not isinstance(enhanced_info['category_tags'], list):
            enhanced_info['category_tags'] = []
        
        return enhanced_info
        
    except Exception as e:
        print(f"è·å–å¢å¼ºä¹¦ç±ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
        # è¿”å›åŸºæœ¬ä¿¡æ¯ä½œä¸ºå¤‡ç”¨
        return {
            'book_id': book_id,
            'book_name': f"æœªçŸ¥å°è¯´_{book_id}",
            'author': "æœªçŸ¥ä½œè€…",
            'description': "æš‚æ— ç®€ä»‹",
            'thumb_url': None,
            'read_count': None,
            'creation_status': None,
            'category_tags': []
        }

def fetch_api_endpoints_from_server():
    """ä»æœåŠ¡å™¨è·å–APIåˆ—è¡¨"""
    try:
        headers = get_headers()
        headers["X-Auth-Token"] = CONFIG["auth_token"]

        response = requests.get(
            CONFIG["server_url"],
            headers=headers,
            timeout=10,
            verify=False
        )

        if response.status_code == 200:
            data = response.json()
            sources = data.get("sources", [])

            CONFIG["api_endpoints"] = []

            for source in sources:
                if source["enabled"]:
                    # æ·»åŠ åˆ°APIç«¯ç‚¹åˆ—è¡¨
                    CONFIG["api_endpoints"].append({
                        "url": source["single_url"],
                        "name": source["name"]
                    })

                    # æ£€æŸ¥æ˜¯å¦æ”¯æŒæ‰¹é‡ä¸‹è½½
                    if source["name"] == CONFIG["batch_config"]["name"]:
                        base_url = source["single_url"].split('?')[0]
                        batch_endpoint = base_url.split('/')[-1]
                        base_url = base_url.rsplit('/', 1)[0] if '/' in base_url else base_url

                        # é…ç½®æ‰¹é‡ä¸‹è½½
                        CONFIG["batch_config"]["base_url"] = base_url
                        CONFIG["batch_config"]["batch_endpoint"] = f"/{batch_endpoint}"
                        CONFIG["batch_config"]["token"] = source.get("token", "")
                        CONFIG["batch_config"]["enabled"] = True

            print("æˆåŠŸä»æœåŠ¡å™¨è·å–APIåˆ—è¡¨!")
            return True
        else:
            print(f"è·å–APIåˆ—è¡¨å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
    except Exception as e:
        print(f"è·å–APIåˆ—è¡¨å¼‚å¸¸: {str(e)}")

def extract_chapters(soup):
    """è§£æç« èŠ‚åˆ—è¡¨"""
    chapters = []
    for idx, item in enumerate(soup.select('div.chapter-item')):
        a_tag = item.find('a')
        if not a_tag:
            continue

        raw_title = a_tag.get_text(strip=True)

        # ç‰¹æ®Šç« èŠ‚
        if re.match(r'^(ç•ªå¤–|ç‰¹åˆ«ç¯‡|ifçº¿)\s*', raw_title):
            final_title = raw_title
        else:
            clean_title = re.sub(
                r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+ç« \s*',
                '',
                raw_title
            ).strip()
            final_title = f"ç¬¬{idx+1}ç«  {clean_title}"

        chapters.append({
            "id": a_tag['href'].split('/')[-1],
            "title": final_title,
            "raw_title": raw_title,
            "url": f"https://fanqienovel.com{a_tag['href']}",
            "index": idx
        })
    return chapters

def batch_download_chapters(item_ids, headers):
    """Dlmilyæ¨¡å¼ä¸‹è½½ç« èŠ‚å†…å®¹"""
    if not CONFIG["batch_config"]["enabled"]:
        print("Dlmilyä¸‹è½½åŠŸèƒ½æœªå¯ç”¨")
        return None

    batch_config = CONFIG["batch_config"]
    url = f"{batch_config['base_url']}{batch_config['batch_endpoint']}"

    try:
        batch_headers = headers.copy()
        if batch_config["token"]:
            batch_headers["token"] = batch_config["token"]
        batch_headers["Content-Type"] = "application/json"

        payload = {"item_ids": item_ids}
        response = make_request(
            url,
            headers=batch_headers,
            method='POST',
            data=json.dumps(payload),
            timeout=batch_config["timeout"],
            verify=False,
            use_tor=True
        )

        if response.status_code == 200:
            data = response.json()

            if isinstance(data, dict) and "data" in data:
                return data["data"]
            return data
        else:
            print(f"Dlmilyä¸‹è½½å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return None

    except Exception as e:
        print(f"Dlmilyä¸‹è½½å¼‚å¸¸ï¼")
        return None

def validate_chapter_mapping(item_ids, results):
    """éªŒè¯ç« èŠ‚IDæ˜ å°„æ˜¯å¦æ­£ç¡®"""
    if not results or not item_ids:
        return False

    # æ£€æŸ¥æ‰€æœ‰è¯·æ±‚çš„ç« èŠ‚IDæ˜¯å¦éƒ½åœ¨ç»“æœä¸­
    missing_ids = [chapter_id for chapter_id in item_ids if chapter_id not in results]
    if missing_ids:
        print(f"è­¦å‘Šï¼šä»¥ä¸‹ç« èŠ‚IDåœ¨ç»“æœä¸­ç¼ºå¤±: {missing_ids}")

    # æ£€æŸ¥ç»“æœä¸­æ˜¯å¦æœ‰æ„å¤–çš„ç« èŠ‚ID
    unexpected_ids = [chapter_id for chapter_id in results.keys() if chapter_id not in item_ids]
    if unexpected_ids:
        print(f"è­¦å‘Šï¼šç»“æœä¸­åŒ…å«æ„å¤–çš„ç« èŠ‚ID: {unexpected_ids}")

    return len(missing_ids) == 0

def validate_chapter_integrity(chapter_results, total_chapters, chapters_info=None):
    """éªŒè¯ç« èŠ‚å®Œæ•´æ€§å’Œè¿ç»­æ€§"""
    if not chapter_results:
        print("è­¦å‘Šï¼šæ²¡æœ‰ç« èŠ‚ç»“æœéœ€è¦éªŒè¯")
        return False, []

    issues = []
    downloaded_indices = set(chapter_results.keys())

    # 1. æ£€æŸ¥ç« èŠ‚ç´¢å¼•è¿ç»­æ€§
    if downloaded_indices:
        min_idx = min(downloaded_indices)
        max_idx = max(downloaded_indices)

        # æ£€æŸ¥æ˜¯å¦æœ‰ä¸­é—´ç« èŠ‚ç¼ºå¤±
        missing_indices = []
        for i in range(min_idx, max_idx + 1):
            if i not in downloaded_indices:
                missing_indices.append(i + 1)  # è½¬ä¸ºäººç±»å¯è¯»çš„ç« èŠ‚å·

        if missing_indices:
            issue = f"æ£€æµ‹åˆ°ç« èŠ‚ç¼ºå¤±ï¼Œç¼ºå¤±ç« èŠ‚å·: {missing_indices}"
            issues.append(issue)
            print(f"å®Œæ•´æ€§æ£€æŸ¥ - {issue}")

    # 2. æ£€æŸ¥ç« èŠ‚å†…å®¹å®Œæ•´æ€§
    empty_content_chapters = []
    for idx, result in chapter_results.items():
        if not result.get("content", "").strip():
            empty_content_chapters.append(idx + 1)

    if empty_content_chapters:
        issue = f"æ£€æµ‹åˆ°ç©ºå†…å®¹ç« èŠ‚: ç¬¬{empty_content_chapters}ç« "
        issues.append(issue)
        print(f"å®Œæ•´æ€§æ£€æŸ¥ - {issue}")

    # 3. æ£€æŸ¥ç« èŠ‚æ ‡é¢˜åˆç†æ€§ï¼ˆå¦‚æœæä¾›äº†ç« èŠ‚ä¿¡æ¯ï¼‰
    if chapters_info:
        title_mismatch_chapters = []
        for idx, result in chapter_results.items():
            if idx < len(chapters_info):
                expected_title = chapters_info[idx]["title"]
                actual_title = result.get("title", "")

                # ç®€å•çš„æ ‡é¢˜åŒ¹é…æ£€æŸ¥
                if (expected_title and actual_title and
                    expected_title not in actual_title and
                    actual_title not in expected_title):
                    title_mismatch_chapters.append({
                        "chapter": idx + 1,
                        "expected": expected_title,
                        "actual": actual_title
                    })

        if title_mismatch_chapters:
            issue = f"æ£€æµ‹åˆ°æ ‡é¢˜ä¸åŒ¹é…ç« èŠ‚: {len(title_mismatch_chapters)}ä¸ª"
            issues.append(issue)
            print(f"å®Œæ•´æ€§æ£€æŸ¥ - {issue}")
            for mismatch in title_mismatch_chapters[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                print(f"  ç¬¬{mismatch['chapter']}ç« : æœŸæœ›'{mismatch['expected']}', å®é™…'{mismatch['actual']}'")

    # 4. æ£€æŸ¥æ€»ä½“å®Œæ•´æ€§
    completion_rate = len(downloaded_indices) / total_chapters if total_chapters > 0 else 0
    if completion_rate < 0.95:  # å¦‚æœå®Œæˆç‡ä½äº95%
        issue = f"ç« èŠ‚å®Œæˆç‡è¾ƒä½: {completion_rate:.1%} ({len(downloaded_indices)}/{total_chapters})"
        issues.append(issue)
        print(f"å®Œæ•´æ€§æ£€æŸ¥ - {issue}")

    is_valid = len(issues) == 0
    if is_valid:
        print(f"ç« èŠ‚å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡: {len(downloaded_indices)}/{total_chapters} ç« èŠ‚ï¼Œå®Œæˆç‡ {completion_rate:.1%}")
    else:
        print(f"ç« èŠ‚å®Œæ•´æ€§æ£€æŸ¥å‘ç° {len(issues)} ä¸ªé—®é¢˜")

    return is_valid, issues

def check_rabbits0209_limit(chapters, config=None):
    """
    æ£€æŸ¥rabbits0209æ¨¡å¼ä¸‹çš„ç« èŠ‚é™åˆ¶
    
    Args:
        chapters: å¾…ä¸‹è½½çš„ç« èŠ‚åˆ—è¡¨
        config: é…ç½®å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å…¨å±€CONFIG
        
    Returns:
        tuple: (is_over_limit, max_chapters, suggested_batches)
            - is_over_limit: æ˜¯å¦è¶…è¿‡é™åˆ¶
            - max_chapters: æœ€å¤§ç« èŠ‚é™åˆ¶
            - suggested_batches: å»ºè®®çš„æ‰¹æ¬¡æ•°
    """
    try:
        # å¯¼å…¥é…ç½®
        if config is None:
            from config import CONFIG
            config = CONFIG
        
        # è·å–rabbits0209é…ç½®
        request_config = config.get("request", {})
        enable_limit = request_config.get("rabbits0209_enable_limit", True)
        max_chapters = request_config.get("rabbits0209_max_chapters", 30)
        
        # å¦‚æœæœªå¯ç”¨é™åˆ¶ï¼Œè¿”å›ä¸è¶…é™
        if not enable_limit:
            return False, max_chapters, 1
        
        chapter_count = len(chapters) if chapters else 0
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é™åˆ¶
        is_over_limit = chapter_count > max_chapters
        
        # è®¡ç®—å»ºè®®çš„æ‰¹æ¬¡æ•°
        if is_over_limit:
            suggested_batches = (chapter_count + max_chapters - 1) // max_chapters
        else:
            suggested_batches = 1
        
        return is_over_limit, max_chapters, suggested_batches
        
    except Exception as e:
        print(f"è­¦å‘Š: æ£€æŸ¥rabbits0209ç« èŠ‚é™åˆ¶æ—¶å‘ç”Ÿé”™è¯¯ {str(e)}")
        # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›å®‰å…¨çš„é»˜è®¤å€¼
        return False, 30, 1

def create_limited_batches(chapters, config=None):
    """
    æ ¹æ®rabbits0209ç« èŠ‚é™åˆ¶åˆ›å»ºæ‰¹æ¬¡
    
    Args:
        chapters: å¾…ä¸‹è½½çš„ç« èŠ‚åˆ—è¡¨
        config: é…ç½®å­—å…¸ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨å…¨å±€CONFIG
        
    Returns:
        list: åˆ†æ‰¹åçš„ç« èŠ‚åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªç« èŠ‚æ‰¹æ¬¡
    """
    try:
        # å¯¼å…¥é…ç½®
        if config is None:
            from config import CONFIG
            config = CONFIG
        
        # è·å–rabbits0209é…ç½®
        request_config = config.get("request", {})
        enable_limit = request_config.get("rabbits0209_enable_limit", True)
        max_chapters = request_config.get("rabbits0209_max_chapters", 30)
        
        if not chapters:
            return []
        
        # å¦‚æœæœªå¯ç”¨é™åˆ¶ï¼Œè¿”å›å•ä¸ªæ‰¹æ¬¡
        if not enable_limit:
            return [chapters]
        
        # ç¡®ä¿ç« èŠ‚æŒ‰ç´¢å¼•æ’åº
        sorted_chapters = sorted(chapters, key=lambda x: x.get("index", 0))
        
        # åˆ†æ‰¹å¤„ç†
        batches = []
        for i in range(0, len(sorted_chapters), max_chapters):
            batch = sorted_chapters[i:i + max_chapters]
            batches.append(batch)
        
        print(f"ç« èŠ‚åˆ†æ‰¹å®Œæˆ: æ€»è®¡ {len(sorted_chapters)} ç« èŠ‚ï¼Œåˆ†ä¸º {len(batches)} æ‰¹ï¼Œæ¯æ‰¹æœ€å¤š {max_chapters} ç« èŠ‚")
        
        return batches
        
    except Exception as e:
        print(f"è­¦å‘Š: åˆ›å»ºç« èŠ‚æ‰¹æ¬¡æ—¶å‘ç”Ÿé”™è¯¯ {str(e)}")
        # å‘ç”Ÿé”™è¯¯æ—¶è¿”å›åŸå§‹ç« èŠ‚ä½œä¸ºå•ä¸ªæ‰¹æ¬¡
        return [chapters] if chapters else []

def qwq_batch_download_chapters(item_ids, headers):
    """rabbits0209æ¨¡å¼æ‰¹é‡ä¸‹è½½ç« èŠ‚å†…å®¹ï¼Œé‡‡ç”¨ä¸¥æ ¼çš„IDéªŒè¯ï¼Œç¡®ä¿ç« èŠ‚é¡ºåºæ­£ç¡®"""
    try:
        # 1. æ„å»ºè¯·æ±‚
        item_ids_str = ",".join(item_ids)
        url = f"https://qwq.tutuxka.top/api/index.php?api=content&item_ids={item_ids_str}&api_type=batch"
        
        print(f"rabbits0209æ‰¹é‡è¯·æ±‚URL: {url}")
        print(f"è¯·æ±‚ç« èŠ‚æ•°: {len(item_ids)}")

        qwq_headers = headers.copy()
        qwq_headers['Accept-Encoding'] = 'gzip, deflate'

        # 2. å‘é€è¯·æ±‚
        response = requests.get(
            url,
            headers=qwq_headers,
            timeout=CONFIG["request_timeout"],
            verify=False
        )
        response.raise_for_status() # æŠ›å‡ºHTTPé”™è¯¯

        # 3. è§£æå’Œä¸¥æ ¼éªŒè¯å“åº”
        data = response.json()
        
        if isinstance(data, dict) and data.get("error"):
            print(f"rabbits0209 APIè¿”å›é”™è¯¯: {data.get('error')}")
            return None

        results = {}
        chapter_list = []

        # ç»Ÿä¸€å¤„ç†ä¸åŒæ ¼å¼çš„æ•°æ®æºï¼Œæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªç« èŠ‚åˆ—è¡¨
        if isinstance(data, dict) and data.get("success") and isinstance(data.get("data"), list):
            chapter_list = data["data"]
            print(f"å¤„ç†æ ‡å‡†APIå“åº”æ ¼å¼ï¼ŒåŒ…å« {len(chapter_list)} ä¸ªç« èŠ‚ã€‚")
        elif isinstance(data, list):
            chapter_list = data
            print(f"å¤„ç†ç›´æ¥åˆ—è¡¨å“åº”æ ¼å¼ï¼ŒåŒ…å« {len(chapter_list)} ä¸ªç« èŠ‚ã€‚")
        else:
            print(f"è­¦å‘Šï¼šAPIè¿”å›äº†æœªçŸ¥çš„æˆ–éåˆ—è¡¨æ ¼å¼çš„æ•°æ®ï¼Œæ‰¹é‡ä¸‹è½½å¤±è´¥ã€‚æ•°æ®ç±»å‹: {type(data)}")
            return None # æœªçŸ¥æ ¼å¼ï¼Œæ‹’ç»å¤„ç†

        # 4. ä¸¥æ ¼çš„IDåŒ¹é…
        if not chapter_list:
            print("è­¦å‘Šï¼šAPIè¿”å›çš„ç« èŠ‚åˆ—è¡¨ä¸ºç©ºï¼Œæ‰¹é‡ä¸‹è½½å¤±è´¥ã€‚")
            return None

        # æ£€æŸ¥è¿”å›çš„ç¬¬ä¸€ä¸ªé¡¹ç›®æ˜¯å¦åŒ…å«'id'ï¼Œè¿™æ˜¯å…³é”®çš„éªŒè¯æ­¥éª¤
        if not isinstance(chapter_list[0], dict):
            print(f"è­¦å‘Šï¼šAPIè¿”å›çš„ç« èŠ‚æ•°æ®ä¸æ˜¯å­—å…¸æ ¼å¼ï¼Œå®é™…ç±»å‹: {type(chapter_list[0])}")
            print("å°†è‡ªåŠ¨é™çº§ä¸ºå•ç« æ¨¡å¼é‡è¯•ï¼Œä»¥ç¡®ä¿é¡ºåºæ­£ç¡®ã€‚")
            return None

        # è°ƒè¯•ï¼šæ‰“å°ç¬¬ä¸€ä¸ªç« èŠ‚çš„é”®å
        first_chapter_keys = list(chapter_list[0].keys())
        print(f"è°ƒè¯•ï¼šç¬¬ä¸€ä¸ªç« èŠ‚åŒ…å«çš„å­—æ®µ: {first_chapter_keys}")

        # æ£€æŸ¥æ˜¯å¦æœ‰IDå­—æ®µï¼ˆå¯èƒ½æ˜¯ä¸åŒçš„å­—æ®µåï¼‰
        id_field = None
        possible_id_fields = ['id', 'item_id', 'chapter_id', 'chapterId', 'itemId']
        for field in possible_id_fields:
            if field in chapter_list[0]:
                id_field = field
                break

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°IDå­—æ®µï¼Œä½†æœ‰contentå­—æ®µï¼Œå°è¯•æŒ‰é¡ºåºå¤„ç†
        if not id_field and 'content' in chapter_list[0]:
            print("è­¦å‘Šï¼šAPIè¿”å›çš„æ•°æ®ç¼ºå°‘IDå­—æ®µï¼Œä½†åŒ…å«contentï¼Œå°è¯•æŒ‰é¡ºåºå¤„ç†...")
            # æŒ‰è¯·æ±‚é¡ºåºå¤„ç†ç« èŠ‚
            for i, chapter_data in enumerate(chapter_list):
                if i < len(item_ids) and isinstance(chapter_data, dict):
                    chapter_id = item_ids[i]  # ä½¿ç”¨è¯·æ±‚çš„IDé¡ºåº
                    content = chapter_data.get("content", "")
                    title = chapter_data.get("title", "")

                    if content and content.strip():  # ç¡®ä¿å†…å®¹ä¸ä¸ºç©º
                        processed_content = process_chapter_content(content)
                        results[chapter_id] = {
                            "content": processed_content,
                            "title": title
                        }
                        print(f"  âœ“ å¤„ç†ç« èŠ‚ {i+1}/{len(chapter_list)}: {title[:30]}...")
                    else:
                        print(f"  âœ— è·³è¿‡ç©ºç« èŠ‚ {i+1}: {title}")

            if results:
                print(f"âœ… æˆåŠŸæŒ‰é¡ºåºå¤„ç†äº† {len(results)}/{len(chapter_list)} ä¸ªç« èŠ‚")
                return results
            else:
                print("âŒ æŒ‰é¡ºåºå¤„ç†å¤±è´¥ï¼Œæ‰€æœ‰ç« èŠ‚å†…å®¹ä¸ºç©º")
                return None

        if not id_field:
            print("è­¦å‘Šï¼šAPIè¿”å›çš„ç« èŠ‚æ•°æ®ä¸­ç¼ºå°‘IDå­—æ®µï¼Œæ— æ³•è¿›è¡Œå®‰å…¨åŒ¹é…ï¼Œæ‰¹é‡ä¸‹è½½å¤±è´¥ã€‚")
            print(f"å°è¯•çš„å­—æ®µå: {possible_id_fields}")
            print("å°†è‡ªåŠ¨é™çº§ä¸ºå•ç« æ¨¡å¼é‡è¯•ï¼Œä»¥ç¡®ä¿é¡ºåºæ­£ç¡®ã€‚")
            return None

        # éå†è¿”å›çš„ç« èŠ‚ï¼Œåªæ¥å—IDåœ¨è¯·æ±‚åˆ—è¡¨ä¸­çš„ç« èŠ‚
        matched_ids = set()
        for chapter_data in chapter_list:
            if not isinstance(chapter_data, dict): continue

            chapter_id = str(chapter_data.get(id_field, ''))
            content = chapter_data.get("content", "")

            if chapter_id in item_ids and content:
                processed_content = process_chapter_content(content)
                results[chapter_id] = {
                    "content": processed_content,
                    "title": chapter_data.get("title", "")
                }
                matched_ids.add(chapter_id)
            elif chapter_id not in item_ids:
                print(f"è­¦å‘Šï¼šAPIè¿”å›äº†æœªè¯·æ±‚çš„ç« èŠ‚ID {chapter_id}ï¼Œå·²å¿½ç•¥ã€‚")

        # 5. æœ€ç»ˆéªŒè¯
        if not results:
            print("è­¦å‘Šï¼šæ‰¹é‡ä¸‹è½½æœªèƒ½æˆåŠŸåŒ¹é…ä»»ä½•ç« èŠ‚ã€‚")
            return None

        print(f"æ‰¹é‡ä¸‹è½½éªŒè¯é€šè¿‡ï¼ŒæˆåŠŸåŒ¹é… {len(results)}/{len(item_ids)} ä¸ªç« èŠ‚ã€‚")
        return results

    except requests.exceptions.RequestException as e:
        print(f"rabbits0209æ‰¹é‡è¯·æ±‚å¤±è´¥: {str(e)}")
        return None
    except json.JSONDecodeError:
        print(f"rabbits0209æ‰¹é‡ä¸‹è½½JSONè§£æå¤±è´¥ã€‚å“åº”å†…å®¹: {response.text[:200]}...")
        return None
    except Exception as e:
        print(f"rabbits0209æ‰¹é‡ä¸‹è½½å‘ç”ŸæœªçŸ¥å¼‚å¸¸: {str(e)}")
        return None

def process_chapter_content(content):
    """å¤„ç†ç« èŠ‚å†…å®¹"""
    if not content or not isinstance(content, str):
        return ""

    try:
        # ç§»é™¤HTMLæ ‡ç­¾
        content = re.sub(r'<header>.*?</header>', '', content, flags=re.DOTALL)
        content = re.sub(r'<footer>.*?</footer>', '', content, flags=re.DOTALL)
        content = re.sub(r'</?article>', '', content)
        content = re.sub(r'<p[^>]*>', '\n    ', content)
        content = re.sub(r'</p>', '', content)
        content = re.sub(r'<[^>]+>', '', content)
        content = re.sub(r'\\u003c|\\u003e', '', content)

        # æ ¼å¼åŒ–æ®µè½
        content = re.sub(r'\n{3,}', '\n\n', content).strip()
        lines = [line.strip() for line in content.split('\n') if line.strip()]
        return '\n'.join(['    ' + line for line in lines])
    except Exception as e:
        print(f"å†…å®¹å¤„ç†é”™è¯¯: {str(e)}")
        return str(content)

def down_text(chapter_id, headers, book_id=None):
    """ä¸‹è½½ç« èŠ‚å†…å®¹"""
    content = ""
    chapter_title = ""

    # åˆå§‹åŒ–APIç«¯ç‚¹çŠ¶æ€
    if not hasattr(down_text, "api_status"):
        down_text.api_status = {endpoint["url"]: {
            "last_response_time": float('inf'),
            "error_count": 0,
            "last_try_time": 0
        } for endpoint in CONFIG["api_endpoints"]}

    # é¡ºåºå°è¯•API
    for endpoint in CONFIG["api_endpoints"]:
        current_endpoint = endpoint["url"].format(chapter_id=chapter_id)
        api_name = endpoint["name"]

        down_text.api_status[endpoint["url"]]["last_try_time"] = time.time()

        try:
            # éšæœºå»¶è¿Ÿ
            time.sleep(random.uniform(0.1, 0.5))

            start_time = time.time()

            # å¯¹qwq APIç‰¹æ®Šå¤„ç†ï¼Œé¿å…Brotliå‹ç¼©é—®é¢˜
            if api_name == "qwq":
                print(f"qwqå•ç« è¯·æ±‚URL: {current_endpoint}")
                qwq_headers = headers.copy()
                qwq_headers['Accept-Encoding'] = 'gzip, deflate'  # ç§»é™¤brå‹ç¼©
                response = requests.get(
                    current_endpoint,
                    headers=qwq_headers,
                    timeout=CONFIG["request_timeout"],
                    verify=False
                )
            else:
                response = make_request(
                    current_endpoint,
                    headers=headers.copy(),
                    timeout=CONFIG["request_timeout"],
                    verify=False,
                    use_tor=True
                )

            response_time = time.time() - start_time
            down_text.api_status[endpoint["url"]].update({
                "last_response_time": response_time,
                "error_count": max(0, down_text.api_status[endpoint["url"]]["error_count"] - 1)
            })

            data = response.json()
            content = data.get("data", {}).get("content", "")
            chapter_title = data.get("data", {}).get("title", "")

            if api_name == "fqphp" and content:
                # å¤„ç†å†…å®¹
                if len(content) > 20:
                    content = content[:-20]

                processed_content = process_chapter_content(content)
                return chapter_title, processed_content

            elif api_name == "lsjk" and content:
                # å¤„ç†å†…å®¹
                paragraphs = re.findall(r'<p idx="\d+">(.*?)</p>', content)
                cleaned_content = "\n".join(p.strip() for p in paragraphs if p.strip())
                formatted_content = '\n'.join('    ' + line if line.strip() else line
                                            for line in cleaned_content.split('\n'))
                return chapter_title, formatted_content

            elif api_name == "qyuing" and data.get("code") == 0 and content:
                processed_content = process_chapter_content(content)
                return chapter_title, processed_content

            elif api_name == "qwq":
                if content:
                    processed_content = process_chapter_content(content)
                    return chapter_title, processed_content
                else:
                    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯ä¿¡æ¯
                    if isinstance(data, dict) and "error" in data:
                        print(f"qwq APIè¿”å›é”™è¯¯: {data.get('error')}")
                        if "trace" in data:
                            print(f"é”™è¯¯è¯¦æƒ…: {data['trace']}")
                    else:
                        print(f"qwq APIè¿”å›ç©ºå†…å®¹")

            print(f"APIè¿”å›ç©ºå†…å®¹ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ªAPI...")
            down_text.api_status[endpoint["url"]]["error_count"] += 1

        except Exception as e:
            print(f"APIè¯·æ±‚å¤±è´¥: {str(e)}")
            down_text.api_status[endpoint["url"]]["error_count"] += 1
            time.sleep(3)

    print(f"æ‰€æœ‰APIå°è¯•å¤±è´¥ï¼Œæ— æ³•ä¸‹è½½ç« èŠ‚ {chapter_id}")
    return None, None

def get_chapters_from_api(book_id, headers):
    """ä»APIè·å–ç« èŠ‚åˆ—è¡¨"""
    try:
        # è·å–ç« èŠ‚åˆ—è¡¨
        page_url = f'https://fanqienovel.com/page/{book_id}'
        response = requests.get(page_url, headers=headers, timeout=CONFIG["request_timeout"])
        soup = bs4.BeautifulSoup(response.text, 'html.parser')
        chapters = extract_chapters(soup)

        # è·å–ç« èŠ‚IDé¡ºåº
        api_url = f"https://fanqienovel.com/api/reader/directory/detail?bookId={book_id}"
        api_response = requests.get(api_url, headers=headers, timeout=CONFIG["request_timeout"])
        api_data = api_response.json()
        chapter_ids = api_data.get("data", {}).get("allItemIds", [])

        # åˆå¹¶æ•°æ®ï¼Œç”ŸæˆæŒ‰APIé¡ºåºçš„ç« èŠ‚åˆ—è¡¨å¹¶ç¡®ä¿æ ‡é¢˜æ­£ç¡®
        final_chapters = []
        for idx, chapter_id in enumerate(chapter_ids):
            # æŸ¥æ‰¾ç½‘é¡µè§£æçš„å¯¹åº”ç« èŠ‚
            web_chapter = next((ch for ch in chapters if ch["id"] == chapter_id), None)

            if web_chapter:
                raw_title = web_chapter.get("raw_title", web_chapter.get("title", "")).strip()
                # æ™ºèƒ½åˆ¤æ–­æ˜¯å¦éœ€è¦æ·»åŠ ç« èŠ‚å·å‰ç¼€
                # å¦‚æœåŸå§‹æ ‡é¢˜æœ¬èº«ä¸åŒ…å« "ç¬¬Xç« " æˆ– "ç•ªå¤–" ç­‰æ ‡è¯†ï¼Œåˆ™æ·»åŠ 
                if not re.match(r'^(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹åç™¾åƒ\d]+ç« |ç•ªå¤–|ç‰¹åˆ«ç¯‡|ifçº¿)', raw_title, re.IGNORECASE):
                    title = f"ç¬¬{idx+1}ç«  {raw_title}"
                else:
                    # å¦åˆ™ç›´æ¥ä½¿ç”¨åŸå§‹æ ‡é¢˜ï¼Œå› ä¸ºå®ƒå·²ç»åŒ…å«äº†ç« èŠ‚ä¿¡æ¯
                    title = raw_title
            else:
                # å¦‚æœåœ¨ç½‘é¡µè§£æç»“æœä¸­æ‰¾ä¸åˆ°ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªåŸºç¡€æ ‡é¢˜
                title = f"ç¬¬{idx+1}ç« "

            final_chapters.append({
                "id": chapter_id,
                "title": title,
                "index": idx
            })

        # åº”ç”¨ç« èŠ‚çŸ«æ­£åŠŸèƒ½
        if CHAPTER_CORRECTION_AVAILABLE and CONFIG.get("chapter_correction", {}).get("enabled", True):
            try:
                corrected_chapters, correction_issues = correct_chapters(final_chapters)

                if correction_issues and CONFIG.get("chapter_correction", {}).get("show_correction_report", True):
                    print("=== ç« èŠ‚çŸ«æ­£æŠ¥å‘Š ===")
                    for issue in correction_issues:
                        print(f"  - {issue}")
                    print(f"å·²å¯¹ {len(final_chapters)} ä¸ªç« èŠ‚è¿›è¡Œæ™ºèƒ½æ’åºçŸ«æ­£")
                    print("=" * 20)

                # æ›´æ–°ç« èŠ‚ç´¢å¼•ä»¥ä¿æŒä¸€è‡´æ€§
                for idx, chapter in enumerate(corrected_chapters):
                    chapter["index"] = idx

                return corrected_chapters

            except Exception as e:
                print(f"ç« èŠ‚çŸ«æ­£è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
                print("å°†ä½¿ç”¨åŸå§‹ç« èŠ‚é¡ºåº")
                return final_chapters

        return final_chapters

    except Exception as e:
        print(f"è·å–ç« èŠ‚åˆ—è¡¨å¤±è´¥: {str(e)}")
        return None


def apply_post_download_correction(downloaded_chapters, book_info=None):
    """
    ä¸‹è½½å®Œæˆååº”ç”¨ç« èŠ‚çŸ«æ­£ï¼Œæä¾›æ›´å¥½çš„ç”¨æˆ·åé¦ˆ
    
    Args:
        downloaded_chapters: å·²ä¸‹è½½çš„ç« èŠ‚åˆ—è¡¨
        book_info: ä¹¦ç±ä¿¡æ¯
    
    Returns:
        (corrected_chapters, correction_report)
    """
    try:
        if not CHAPTER_CORRECTION_AVAILABLE:
            return downloaded_chapters, "ç« èŠ‚çŸ«æ­£æ¨¡å—ä¸å¯ç”¨"
            
        correction_config = CONFIG.get("chapter_correction", {})
        if not correction_config.get("enabled", True):
            return downloaded_chapters, "ç« èŠ‚çŸ«æ­£åŠŸèƒ½å·²ç¦ç”¨"
        
        print("\nğŸ”§ æ­£åœ¨è¿›è¡Œä¸‹è½½åç« èŠ‚çŸ«æ­£...")
        
        # å‡†å¤‡ç« èŠ‚æ•°æ®ç”¨äºçŸ«æ­£
        chapters_for_correction = []
        for i, chapter in enumerate(downloaded_chapters):
            chapters_for_correction.append({
                "id": chapter.get("id", str(i)),
                "title": chapter.get("title", f"ç¬¬{i+1}ç« "),
                "index": i
            })
        
        # æ‰§è¡ŒçŸ«æ­£
        corrected_chapters, issues = correct_chapters(chapters_for_correction)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é¡ºåºå˜åŒ–
        original_order = [ch["title"] for ch in chapters_for_correction]
        corrected_order = [ch["title"] for ch in corrected_chapters]
        has_changes = original_order != corrected_order
        
        # ç”ŸæˆæŠ¥å‘Š
        report_lines = []
        report_lines.append("=== ğŸ“š ä¸‹è½½åç« èŠ‚çŸ«æ­£æŠ¥å‘Š ===")
        
        if book_info:
            report_lines.append(f"ä¹¦ç±: {book_info.get('book_name', 'æœªçŸ¥')}")
        
        report_lines.append(f"æ€»ç« èŠ‚æ•°: {len(downloaded_chapters)}")
        
        if has_changes:
            report_lines.append("âœ… ç« èŠ‚é¡ºåºå·²é‡æ–°ä¼˜åŒ–")
            
            # æ˜¾ç¤ºå…³é”®å˜åŒ–
            changes_count = sum(1 for o, c in zip(original_order, corrected_order) if o != c)
            report_lines.append(f"è°ƒæ•´äº† {changes_count} ä¸ªç« èŠ‚çš„ä½ç½®")
            
            # æ˜¾ç¤ºå‰3ä¸ªé‡è¦å˜åŒ–
            shown = 0
            for i, (orig, corr) in enumerate(zip(original_order, corrected_order)):
                if orig != corr and shown < 3:
                    report_lines.append(f"  ä½ç½® {i+1}: '{orig}' â†’ '{corr}'")
                    shown += 1
            
            if changes_count > 3:
                report_lines.append(f"  ... è¿˜æœ‰ {changes_count - 3} ä¸ªå…¶ä»–è°ƒæ•´")
        else:
            report_lines.append("â„¹ï¸ ç« èŠ‚é¡ºåºå·²æ˜¯æœ€ä¼˜ï¼Œæ— éœ€è°ƒæ•´")
        
        if issues:
            report_lines.append("ğŸ” å¤„ç†çš„é—®é¢˜:")
            for issue in issues:
                report_lines.append(f"  - {issue}")
        
        report_lines.append("=" * 30)
        report = "\n".join(report_lines)
        
        # æ˜¾ç¤ºæŠ¥å‘Š
        if correction_config.get("show_correction_report", True):
            print(report)
        
        # å¦‚æœæœ‰å˜åŒ–ï¼Œé‡æ–°æ„å»ºä¸‹è½½ç« èŠ‚æ•°æ®
        if has_changes:
            final_chapters = []
            for corrected_ch in corrected_chapters:
                # æ‰¾åˆ°å¯¹åº”çš„åŸå§‹ç« èŠ‚æ•°æ®
                original_ch = next(
                    (ch for ch in downloaded_chapters if ch.get("id") == corrected_ch["id"]), 
                    None
                )
                
                if original_ch:
                    # ä¿æŒåŸæœ‰æ•°æ®ç»“æ„ï¼Œåªæ›´æ–°æ ‡é¢˜å’Œç´¢å¼•
                    updated_ch = original_ch.copy()
                    updated_ch["title"] = corrected_ch["title"]
                    updated_ch["corrected_index"] = len(final_chapters)
                    final_chapters.append(updated_ch)
            
            return final_chapters, report
        else:
            return downloaded_chapters, report
        
    except Exception as e:
        error_msg = f"ç« èŠ‚çŸ«æ­£è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
        print(error_msg)
        return downloaded_chapters, error_msg

def get_book_info(book_id, headers):
    """è·å–ä¹¦ç±å®Œæ•´ä¿¡æ¯ - å¢å¼ºç‰ˆï¼Œä»å®˜ç½‘HTMLè§£æå®Œæ•´ä¿¡æ¯"""
    url = f'https://fanqienovel.com/page/{book_id}'
    try:
                # ä½¿ç”¨æ™®é€šæµè§ˆå™¨å¤´è¯·æ±‚ HTML é¡µé¢ï¼Œé¿å… Ajax JSON å“åº”
        html_headers = {k: v for k, v in headers.items() if k not in ['Accept', 'X-Requested-With']}
        html_headers['Accept'] = 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'
        response = requests.get(url, headers=html_headers, timeout=CONFIG["request_timeout"])

        if response.status_code != 200:
            print(f"ç½‘ç»œè¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
            return None

        soup = bs4.BeautifulSoup(response.text, 'html.parser')

        # è·å–ä¹¦å
        name_element = soup.find('h1')
        name = name_element.text.strip() if name_element else "æœªçŸ¥ä¹¦å"

        # è·å–ä½œè€…
        author_name = "æœªçŸ¥ä½œè€…"
        author_name_element = soup.find('div', class_='author-name')
        if author_name_element:
            author_name_span = author_name_element.find('span', class_='author-name-text')
            if author_name_span:
                author_name = author_name_span.text.strip()

        # è·å–ç®€ä»‹
        description = "æš‚æ— ç®€ä»‹"
        description_element = soup.find('div', class_='page-abstract-content')
        if description_element:
            description_p = description_element.find('p')
            if description_p:
                # ä¿æŒæ¢è¡Œæ ¼å¼
                description = description_p.get_text(separator='\n', strip=True)
            else:
                description = description_element.get_text(separator='\n', strip=True)

        # è·å–å°é¢å›¾ç‰‡URL
        cover_url = ""
        cover_element = soup.find('img', class_='book-cover-img')
        if cover_element and cover_element.get('src'):
            cover_url = cover_element.get('src')

        # è·å–å®Œç»“çŠ¶æ€å’Œç±»å‹æ ‡ç­¾
        status = "è¿è½½ä¸­"  # é»˜è®¤çŠ¶æ€
        tags = []

        # è§£ææ ‡ç­¾ä¿¡æ¯
        label_elements = soup.find_all('span', class_='info-label-yellow') + soup.find_all('span', class_='info-label-grey')
        for label in label_elements:
            label_text = label.text.strip()
            if label_text in ['å·²å®Œç»“', 'è¿è½½ä¸­', 'å®Œç»“']:
                status = 'å·²å®Œç»“' if label_text in ['å·²å®Œç»“', 'å®Œç»“'] else 'è¿è½½ä¸­'
            else:
                tags.append(label_text)

        # è·å–å­—æ•°ä¿¡æ¯
        word_count = ""
        word_element = soup.find('div', class_='info-count-word')
        if word_element:
            detail_span = word_element.find('span', class_='detail')
            text_span = word_element.find('span', class_='text')
            if detail_span and text_span:
                word_count = f"{detail_span.text.strip()}{text_span.text.strip()}"

        # è·å–æœ€åæ›´æ–°æ—¶é—´
        last_update = ""
        time_element = soup.find('span', class_='info-last-time')
        if time_element:
            last_update = time_element.text.strip()

        print(f"æˆåŠŸè·å–ä¹¦ç±ä¿¡æ¯: {name}")
        print(f"ä½œè€…: {author_name}")
        print(f"çŠ¶æ€: {status}")
        print(f"æ ‡ç­¾: {', '.join(tags) if tags else 'æ— '}")
        print(f"å­—æ•°: {word_count}")
        print(f"æœ€åæ›´æ–°: {last_update}")

        return {
            'name': name,
            'author': author_name,
            'description': description,
            'cover_url': cover_url,
            'status': status,
            'tags': tags,
            'word_count': word_count,
            'last_update': last_update
        }

    except Exception as e:
        print(f"è·å–ä¹¦ç±ä¿¡æ¯å¤±è´¥: {str(e)}")
        return None

def load_status(save_path, book_id=None):
    """åŠ è½½ä¸‹è½½çŠ¶æ€"""
    # ä¼˜å…ˆä½¿ç”¨åŸºäºä¹¦ç±IDçš„çŠ¶æ€æ–‡ä»¶æ ¼å¼
    try:
        from config import CONFIG as USER_CONFIG
        status_file_format = USER_CONFIG.get("file", {}).get("status_file_format", ".{book_id}.download_status")
        if book_id and "{book_id}" in status_file_format:
            status_filename = status_file_format.format(book_id=book_id)
        else:
            # å›é€€åˆ°åŸæ¥çš„æ ¼å¼
            status_filename = CONFIG["status_file"]
    except:
        # å¦‚æœé…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
        if book_id:
            status_filename = f".{book_id}.download_status"
        else:
            status_filename = CONFIG["status_file"]
    
    # åˆ›å»ºçŠ¶æ€æ–‡ä»¶å­ç›®å½•
    status_dir = os.path.join(save_path, ".tomato_status")
    os.makedirs(status_dir, exist_ok=True)
    
    # æ–°çš„çŠ¶æ€æ–‡ä»¶è·¯å¾„
    new_status_file = os.path.join(status_dir, status_filename)
    
    # æ£€æŸ¥æ–°ä½ç½®çš„çŠ¶æ€æ–‡ä»¶
    if os.path.exists(new_status_file):
        try:
            with open(new_status_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    return set(data)
                return set()
        except:
            pass
    
    # å‘åå…¼å®¹ï¼šæ£€æŸ¥æ—§ä½ç½®çš„çŠ¶æ€æ–‡ä»¶
    old_status_file = os.path.join(save_path, status_filename)
    if os.path.exists(old_status_file):
        try:
            with open(old_status_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, list):
                    downloaded_set = set(data)
                    # è¿ç§»åˆ°æ–°ä½ç½®
                    try:
                        with open(new_status_file, 'w', encoding='utf-8') as new_f:
                            json.dump(list(downloaded_set), new_f, ensure_ascii=False, indent=2)
                        # åˆ é™¤æ—§æ–‡ä»¶
                        os.remove(old_status_file)
                        print(f"å·²è¿ç§»çŠ¶æ€æ–‡ä»¶åˆ°æ–°ä½ç½®: {status_dir}")
                    except:
                        pass  # è¿ç§»å¤±è´¥æ—¶é™é»˜å¤„ç†
                    return downloaded_set
                return set()
        except:
            pass
    
    return set()

def save_status(save_path, downloaded, book_id=None):
    """ä¿å­˜ä¸‹è½½çŠ¶æ€"""
    # ä¼˜å…ˆä½¿ç”¨åŸºäºä¹¦ç±IDçš„çŠ¶æ€æ–‡ä»¶æ ¼å¼
    try:
        from config import CONFIG as USER_CONFIG
        status_file_format = USER_CONFIG.get("file", {}).get("status_file_format", ".{book_id}.download_status")
        if book_id and "{book_id}" in status_file_format:
            status_filename = status_file_format.format(book_id=book_id)
        else:
            # å›é€€åˆ°åŸæ¥çš„æ ¼å¼
            status_filename = CONFIG["status_file"]
    except:
        # å¦‚æœé…ç½®åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ ¼å¼
        if book_id:
            status_filename = f".{book_id}.download_status"
        else:
            status_filename = CONFIG["status_file"]
    
    # åˆ›å»ºçŠ¶æ€æ–‡ä»¶å­ç›®å½•
    status_dir = os.path.join(save_path, ".tomato_status")
    os.makedirs(status_dir, exist_ok=True)
    
    status_file = os.path.join(status_dir, status_filename)
    with open(status_file, 'w', encoding='utf-8') as f:
        json.dump(list(downloaded), f, ensure_ascii=False, indent=2)


def Run(book_id, save_path):
    """è¿è¡Œä¸‹è½½"""
    def signal_handler(sig, frame):
        print("\næ£€æµ‹åˆ°ç¨‹åºä¸­æ–­ï¼Œæ­£åœ¨ä¿å­˜å·²ä¸‹è½½å†…å®¹...")
        write_downloaded_chapters_in_order()
        save_status(save_path, downloaded, book_id)
        print(f"å·²ä¿å­˜ {len(downloaded)} ä¸ªç« èŠ‚çš„è¿›åº¦")
        sys.exit(0)

    def write_downloaded_chapters_in_order():
        """æŒ‰ç« èŠ‚é¡ºåºå†™å…¥ï¼ŒåŒ…å«å®Œæ•´æ€§æ£€æŸ¥"""
        if not chapter_results:
            return

        # æ‰§è¡Œç« èŠ‚å®Œæ•´æ€§æ£€æŸ¥
        is_valid, issues = validate_chapter_integrity(chapter_results, len(chapters), chapters)

        if not is_valid:
            print("è­¦å‘Šï¼šç« èŠ‚å®Œæ•´æ€§æ£€æŸ¥å‘ç°é—®é¢˜ï¼Œä½†ä»å°†å†™å…¥å·²ä¸‹è½½çš„ç« èŠ‚")
            for issue in issues:
                print(f"  - {issue}")

        with open(output_file_path, 'w', encoding='utf-8') as f:
            f.write(f"å°è¯´å: {name}\nä½œè€…: {author_name}\nå†…å®¹ç®€ä»‹: {description}\n\n")

            # å¦‚æœæœ‰å®Œæ•´æ€§é—®é¢˜ï¼Œåœ¨æ–‡ä»¶å¼€å¤´æ·»åŠ è­¦å‘Š
            if not is_valid:
                f.write("=" * 50 + "\n")
                f.write("è­¦å‘Šï¼šæœ¬æ–‡ä»¶å¯èƒ½å­˜åœ¨ç« èŠ‚å®Œæ•´æ€§é—®é¢˜\n")
                for issue in issues:
                    f.write(f"- {issue}\n")
                f.write("=" * 50 + "\n\n")

            for idx in range(len(chapters)):
                if idx in chapter_results:
                    result = chapter_results[idx]
                    title = result["title"]
                    f.write(f"{title}\n{result['content']}\n\n")

    # ä¿¡å·å¤„ç†
    signal.signal(signal.SIGINT, signal_handler)

    try:
        headers = get_headers()
        chapters = get_chapters_from_api(book_id, headers)
        if not chapters:
            print("æœªæ‰¾åˆ°ä»»ä½•ç« èŠ‚ï¼Œè¯·æ£€æŸ¥å°è¯´IDæ˜¯å¦æ­£ç¡®ã€‚")
            return

        book_info = get_book_info(book_id, headers)
        if book_info:
            name = book_info.get('name', f"æœªçŸ¥å°è¯´_{book_id}")
            author_name = book_info.get('author', "æœªçŸ¥ä½œè€…")
            description = book_info.get('description', "æš‚æ— ç®€ä»‹")
        else:
            name = f"æœªçŸ¥å°è¯´_{book_id}"
            author_name = "æœªçŸ¥ä½œè€…"
            description = "æš‚æ— ç®€ä»‹"
            description = "æ— ç®€ä»‹"

        downloaded = load_status(save_path, book_id)
        if downloaded:
            print(f"æ£€æµ‹åˆ°æ‚¨æ›¾ç»ä¸‹è½½è¿‡å°è¯´ã€Š{name}ã€‹ã€‚")
            if input("æ˜¯å¦éœ€è¦å†æ¬¡ä¸‹è½½ï¼Ÿ(y/n)ï¼š") != "y":
                print("å·²å–æ¶ˆä¸‹è½½")
                return

        todo_chapters = [ch for ch in chapters if ch["id"] not in downloaded]
        if not todo_chapters:
            print("æ‰€æœ‰ç« èŠ‚å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€ä¸‹è½½")
            return

        print(f"å¼€å§‹ä¸‹è½½ï¼šã€Š{name}ã€‹, æ€»ç« èŠ‚æ•°: {len(chapters)}, å¾…ä¸‹è½½: {len(todo_chapters)}")
        os.makedirs(save_path, exist_ok=True)

        output_file_path = os.path.join(save_path, f"{name}.txt")
        if not os.path.exists(output_file_path):
            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(f"å°è¯´å: {name}\nä½œè€…: {author_name}\nå†…å®¹ç®€ä»‹: {description}\n\n")

        success_count = 0
        failed_chapters = []
        chapter_results = {}
        lock = threading.Lock()

        # Dlmilyä¸‹è½½ - å‘½ä»¤è¡Œæ¨¡å¼é»˜è®¤ä½¿ç”¨Dlmilyä¸‹è½½
        if (CONFIG["batch_config"]["enabled"] and
            any(ep["name"] == "qyuing" for ep in CONFIG["api_endpoints"])):
            print("å¯ç”¨Dlmilyä¸‹è½½æ¨¡å¼...")
            batch_size = CONFIG["batch_config"]["max_batch_size"]

            with tqdm(total=len(todo_chapters), desc="Dlmilyä¸‹è½½è¿›åº¦") as pbar:
                for i in range(0, len(todo_chapters), batch_size):
                    batch = todo_chapters[i:i + batch_size]
                    item_ids = [chap["id"] for chap in batch]

                    batch_results = batch_download_chapters(item_ids, headers)
                    if not batch_results:
                        print(f"ç¬¬ {i//batch_size + 1} æ‰¹ä¸‹è½½å¤±è´¥")
                        failed_chapters.extend(batch)
                        pbar.update(len(batch))
                        continue

                    # å¤„ç†å¹¶å†™å…¥å†…å®¹
                    for chap in batch:
                        # ä»ç»“æœä¸­è·å–å†…å®¹
                        content = batch_results.get(chap["id"], "")
                        if isinstance(content, dict):
                            content = content.get("content", "")

                        if content:
                            processed = process_chapter_content(content)
                            with lock:
                                chapter_results[chap["index"]] = {
                                    "title": chap["title"],
                                    "content": processed
                                }
                                downloaded.add(chap["id"])
                                success_count += 1
                        else:
                            with lock:
                                failed_chapters.append(chap)
                        pbar.update(1)

            todo_chapters = failed_chapters.copy()
            failed_chapters = []
            write_downloaded_chapters_in_order()
            save_status(save_path, downloaded, book_id)

        # rabbits0209ä¸‹è½½
        def download_task(chapter):
            nonlocal success_count
            try:
                title, content = down_text(chapter["id"], headers, book_id)
                if content:
                    with lock:
                        chapter_results[chapter["index"]] = {
                            "title": title or chapter["title"],
                            "content": content
                        }
                        downloaded.add(chapter["id"])
                        success_count += 1
                else:
                    with lock:
                        failed_chapters.append(chapter)
            except Exception as e:
                print(f"ç« èŠ‚ {chapter['id']} ä¸‹è½½å¤±è´¥: {str(e)}")
                with lock:
                    failed_chapters.append(chapter)

        attempt = 1
        while todo_chapters:
            print(f"\nç¬¬ {attempt} æ¬¡å°è¯•ï¼Œå‰©ä½™ {len(todo_chapters)} ä¸ªç« èŠ‚...")
            attempt += 1

            with ThreadPoolExecutor(max_workers=CONFIG["max_workers"]) as executor:
                futures = [executor.submit(download_task, ch) for ch in todo_chapters]

                with tqdm(total=len(todo_chapters), desc="rabbits0209ä¸‹è½½è¿›åº¦") as pbar:
                    for _ in as_completed(futures):
                        pbar.update(1)

            write_downloaded_chapters_in_order()
            save_status(save_path, downloaded, book_id)
            todo_chapters = failed_chapters.copy()
            failed_chapters = []

            if todo_chapters:
                time.sleep(1)

        print(f"ä¸‹è½½å®Œæˆï¼æˆåŠŸä¸‹è½½ {success_count} ä¸ªç« èŠ‚")

    except Exception as e:
        print(f"è¿è¡Œé”™è¯¯: {str(e)}")
        if 'downloaded' in locals():
            write_downloaded_chapters_in_order()
            save_status(save_path, downloaded, book_id)

# GUIä¸‹è½½å™¨ç±»ï¼Œç”¨äºå…¼å®¹ç°æœ‰çš„GUIä»£ç 
class GUIdownloader:
    """GUIä¸‹è½½å™¨ç±»ï¼Œç”¨äºåœ¨GUIç¯å¢ƒä¸­ä¸‹è½½å°è¯´"""

    def __init__(self, book_id: str, save_path: str, status_callback: callable, progress_callback: callable, 
                 output_format: str = "TXT", generate_epub_when_txt: bool = False, download_mode: str = "batch"):
        self.book_id = book_id
        self.save_path = save_path
        self.status_callback = status_callback
        self.progress_callback = progress_callback
        self.output_format = output_format
        self.generate_epub_when_txt = generate_epub_when_txt
        self.download_mode = download_mode  # 'batch'(Dlmily) or 'single'(rabbits0209)
        self.stop_flag = False
        self.start_time = time.time()

    def _generate_book_header(self, name: str, author_name: str, description: str, enhanced_info: dict = None) -> str:
        """ç”ŸæˆåŒ…å«è¯¦ç»†ä¿¡æ¯çš„ä¹¦ç±å¤´éƒ¨"""
        import datetime
        
        header = f"ä¹¦å: {name}\n"
        header += f"ä½œè€…: {author_name}\n"
        
        if enhanced_info:
            # æ·»åŠ è¯¦ç»†ä¿¡æ¯
            read_count = enhanced_info.get('read_count')
            creation_status = enhanced_info.get('creation_status')
            category_tags = enhanced_info.get('category_tags', [])
            # ç¡®ä¿åˆ—è¡¨é¡¹ä¸º dictï¼Œä¾¿äºåç»­ä½¿ç”¨ tag.get
            category_tags = [{'category_name': tag} if isinstance(tag, str) else tag for tag in category_tags]
            book_id = enhanced_info.get('book_id', '')
            
            if read_count:
                header += f"é˜…è¯»é‡: {read_count}\n"
            
            if creation_status is not None:
                # å¤„ç†ä¸åŒç±»å‹çš„çŠ¶æ€å€¼
                if creation_status == "0" or creation_status == 0:
                    status_text = "å®Œç»“"
                elif creation_status == "1" or creation_status == 1:
                    status_text = "è¿è½½ä¸­"
                else:
                    status_text = f"æœªçŸ¥çŠ¶æ€({creation_status})"
                header += f"è¿è½½çŠ¶æ€: {status_text}\n"
            
            if category_tags:
                categories = [tag.get('category_name', '') for tag in category_tags if tag.get('category_name')]
                if categories:
                    header += f"åˆ†ç±»: {' | '.join(categories)}\n"
            
            if book_id:
                header += f"ä¹¦ç±ID: {book_id}\n"
        
        header += f"ä¸‹è½½æ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        header += f"æ¥æº: ç•ªèŒ„å°è¯´\n"
        header += f"å†…å®¹ç®€ä»‹: {description}\n"
        header += f"{'='*50}\n\n"
        
        return header

    def stop_download(self):
        """åœæ­¢ä¸‹è½½"""
        self.stop_flag = True
        if self.status_callback:
            self.status_callback("ä¸‹è½½å·²åœæ­¢")

    def run(self):
        """è¿è¡Œä¸‹è½½"""
        # ä½¿ç”¨ç”¨æˆ·é…ç½®çš„çº¿ç¨‹æ•°è¦†ç›–é»˜è®¤å€¼
        try:
            from config import CONFIG as user_config
            CONFIG["max_workers"] = user_config.get("request", {}).get("max_workers", CONFIG.get("max_workers", 4))
            # è¦†ç›–è¯·æ±‚é™é€Ÿ
            CONFIG["request_rate_limit"] = user_config.get("request", {}).get("request_rate_limit", CONFIG.get("request_rate_limit", 0))
            # è¦†ç›–è¯·æ±‚è¶…æ—¶
            CONFIG["request_timeout"] = user_config.get("request", {}).get("timeout", CONFIG.get("request_timeout", 15))
            # æ³¨æ„ï¼šä¸è¦†ç›–ä¸‹è½½æ¨¡å¼ï¼Œä¼˜å…ˆä½¿ç”¨GUIä¼ å…¥çš„å€¼
            # self.download_mode ä¿æŒGUIä¼ å…¥çš„å€¼ä¸å˜
        except Exception:
            pass
        try:
            if self.status_callback:
                self.status_callback("æ­£åœ¨åˆå§‹åŒ–...")

            # ä»æœåŠ¡å™¨è·å–APIåˆ—è¡¨
            fetch_api_endpoints_from_server()

            if self.status_callback:
                self.status_callback("æ­£åœ¨è·å–å°è¯´ä¿¡æ¯...")

            headers = get_headers()
            chapters = get_chapters_from_api(self.book_id, headers)
            if not chapters:
                if self.status_callback:
                    self.status_callback("æœªæ‰¾åˆ°ä»»ä½•ç« èŠ‚ï¼Œè¯·æ£€æŸ¥å°è¯´IDæ˜¯å¦æ­£ç¡®")
                return

            # è·å–ä¹¦ç±ä¿¡æ¯ï¼ˆæ™ºèƒ½åˆå¹¶å¤šä¸ªæ¥æºçš„æ•°æ®ï¼‰
            enhanced_info = get_enhanced_book_info(self.book_id)
            
            if enhanced_info:
                name = enhanced_info.get('book_name', 'æœªçŸ¥ä¹¦å')
                author_name = enhanced_info.get('author', 'æœªçŸ¥ä½œè€…')
                description = enhanced_info.get('description', 'æš‚æ— ç®€ä»‹')
                
                if self.status_callback:
                    self.status_callback(f"è·å–åˆ°è¯¦ç»†ä¹¦ç±ä¿¡æ¯: ã€Š{name}ã€‹ - {author_name}")
                    
                    # æ˜¾ç¤ºé¢å¤–çš„è¯¦ç»†ä¿¡æ¯
                    read_count = enhanced_info.get('read_count')
                    creation_status = enhanced_info.get('creation_status')
                    category_tags = enhanced_info.get('category_tags', [])
                    # ç¡®ä¿åˆ—è¡¨é¡¹ä¸º dictï¼Œä¾¿äºåç»­ä½¿ç”¨ tag.get
                    category_tags = [{'category_name': tag} if isinstance(tag, str) else tag for tag in category_tags]
                    word_count = enhanced_info.get('word_count')
                    last_update = enhanced_info.get('last_update')

                    if read_count:
                        self.status_callback(f"é˜…è¯»é‡: {read_count}")

                    if creation_status is not None:
                        # è½¬æ¢çŠ¶æ€ç ä¸ºå¯è¯»æ–‡æœ¬
                        if creation_status == "0" or creation_status == 0:
                            status_text = "å®Œç»“"
                        elif creation_status == "1" or creation_status == 1:
                            status_text = "è¿è½½ä¸­"
                        else:
                            status_text = f"æœªçŸ¥çŠ¶æ€({creation_status})"
                        self.status_callback(f"çŠ¶æ€: {status_text}")

                    if word_count:
                        self.status_callback(f"å­—æ•°: {word_count}")

                    if last_update:
                        self.status_callback(f"æœ€åæ›´æ–°: {last_update}")

                    if category_tags:
                        # å¤„ç†ä¸åŒæ ¼å¼çš„æ ‡ç­¾
                        if isinstance(category_tags, list) and category_tags:
                            # å¦‚æœæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨
                            if isinstance(category_tags[0], str):
                                self.status_callback(f"åˆ†ç±»æ ‡ç­¾: {' | '.join(category_tags)}")
                            # å¦‚æœæ˜¯å­—å…¸åˆ—è¡¨ï¼ˆæ¥è‡ªæœç´¢APIï¼‰ï¼Œæå–category_name
                            elif isinstance(category_tags[0], dict):
                                categories = [tag.get('category_name', '') for tag in category_tags if tag.get('category_name')]
                                if categories:
                                    self.status_callback(f"åˆ†ç±»æ ‡ç­¾: {' | '.join(categories)}")

                    if enhanced_info.get('thumb_url'):
                        self.status_callback("æ£€æµ‹åˆ°å°é¢å›¾ç‰‡ï¼ŒEPUBç‰ˆæœ¬å°†åŒ…å«å°é¢")
            else:
                # å¦‚æœå®Œå…¨è·å–å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨ä¿¡æ¯
                name = f"æœªçŸ¥å°è¯´_{self.book_id}"
                author_name = "æœªçŸ¥ä½œè€…"
                description = "æ— ç®€ä»‹"
                enhanced_info = None
                
                if self.status_callback:
                    self.status_callback("æ— æ³•è·å–ä¹¦ç±è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨é»˜è®¤ä¿¡æ¯")

            if self.status_callback:
                self.status_callback(f"å¼€å§‹ä¸‹è½½ï¼šã€Š{name}ã€‹")

            downloaded = load_status(self.save_path, self.book_id)
            todo_chapters = [ch for ch in chapters if ch["id"] not in downloaded]

            # è®¡ç®—æ€»ç« èŠ‚æ•°å’Œå·²ä¸‹è½½ç« èŠ‚æ•°
            total_chapters = len(chapters)
            already_downloaded = len(downloaded)

            # è°ƒè¯•ä¿¡æ¯
            if self.status_callback:
                self.status_callback(f"æ€»ç« èŠ‚æ•°: {total_chapters}, å·²ä¸‹è½½: {already_downloaded}, å¾…ä¸‹è½½: {len(todo_chapters)}")

            # è®¾ç½®åˆå§‹è¿›åº¦ï¼ˆåŸºäºå·²ä¸‹è½½çš„ç« èŠ‚ï¼‰
            initial_progress = int(already_downloaded / total_chapters * 100) if total_chapters > 0 else 0
            if self.progress_callback:
                self.progress_callback(initial_progress)
                
            # è°ƒè¯•ä¿¡æ¯
            if self.status_callback:
                self.status_callback(f"è®¾ç½®åˆå§‹è¿›åº¦: {initial_progress}%")

            if not todo_chapters:
                if self.status_callback:
                    self.status_callback("æ‰€æœ‰ç« èŠ‚å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€ä¸‹è½½")
                if self.progress_callback:
                    self.progress_callback(100)
                return

            os.makedirs(self.save_path, exist_ok=True)

            output_file_path = os.path.join(self.save_path, f"{name}.txt")
            if not os.path.exists(output_file_path):
                with open(output_file_path, 'w', encoding='utf-8') as f:
                    f.write(f"å°è¯´å: {name}\nä½œè€…: {author_name}\nå†…å®¹ç®€ä»‹: {description}\n\n")

            success_count = 0
            failed_chapters = []
            chapter_results = {}
            import threading
            lock = threading.Lock()

            # è®°å½•Dlmilyä¸‹è½½çš„æˆåŠŸæ•°é‡ï¼Œé¿å…é‡å¤è®¡ç®—
            batch_success_count = 0

            # æ ¹æ®ä¸‹è½½æ¨¡å¼è®¾ç½®APIåˆ—è¡¨ - å¿…é¡»åœ¨Dlmilyä¸‹è½½åˆ¤æ–­ä¹‹å‰è®¾ç½®
            if self.download_mode == 'single':
                # rabbits0209æ¨¡å¼ï¼šå¼ºåˆ¶ä½¿ç”¨qwq APIï¼Œæ¸…é™¤å…¶ä»–APIé¿å…Dlmilyä¸‹è½½è¯¯åˆ¤
                # qwq APIç»Ÿä¸€ä½¿ç”¨item_idså‚æ•°ï¼Œå•ç« å’Œæ‰¹é‡éƒ½ä½¿ç”¨ç›¸åŒçš„åŸºç¡€URLæ ¼å¼
                CONFIG["api_endpoints"] = [{"name": "qwq", "url": "https://qwq.tutuxka.top/api/index.php?api=content&item_ids={chapter_id}"}]
                # åŒæ—¶ç¦ç”¨Dlmilyä¸‹è½½é…ç½®ï¼Œç¡®ä¿ä¸ä¼šè§¦å‘Dlmilyä¸‹è½½
                CONFIG["batch_config"]["enabled"] = False
                if self.status_callback:
                    self.status_callback("å·²è®¾ç½®ä¸ºrabbits0209ä¸‹è½½æ¨¡å¼ï¼Œä½¿ç”¨qwq API")

            # Dlmilyä¸‹è½½æ¨¡å¼ - åªæœ‰åœ¨æ˜ç¡®é€‰æ‹©batchæ¨¡å¼æ—¶æ‰æ‰§è¡Œ
            if self.download_mode == 'batch' and\
                CONFIG["batch_config"]["enabled"] and\
                any(ep["name"] == "qyuing" for ep in CONFIG["api_endpoints"]):

                if self.status_callback:
                    self.status_callback("å¯ç”¨Dlmilyä¸‹è½½æ¨¡å¼...")

                batch_size = CONFIG["batch_config"]["max_batch_size"]
                total_batches = (len(todo_chapters) + batch_size - 1) // batch_size

                for batch_idx in range(0, len(todo_chapters), batch_size):
                    if self.stop_flag:
                        break

                    batch = todo_chapters[batch_idx:batch_idx + batch_size]
                    current_batch = batch_idx // batch_size + 1

                    if self.status_callback:
                        self.status_callback(f"Dlmilyä¸‹è½½ç¬¬ {current_batch}/{total_batches} æ‰¹ ({len(batch)} ç« èŠ‚)")

                    item_ids = [chap["id"] for chap in batch]

                    # Dlmityç«‹å³é‡è¯•æœºåˆ¶
                    immediate_retry_enabled = CONFIG.get("request", {}).get("immediate_retry", True)
                    batch_results = None
                    batch_retry_count = 0
                    max_batch_retries = CONFIG.get("request", {}).get("max_retries", 3) if immediate_retry_enabled else 1

                    while batch_retry_count < max_batch_retries and not batch_results:
                        if batch_retry_count > 0 and immediate_retry_enabled:
                            print(f"[Dlmityæ‰¹æ¬¡ {current_batch}] ç¬¬ {batch_retry_count + 1} æ¬¡å°è¯•...")
                            if self.status_callback:
                                self.status_callback(f"Dlmityæ‰¹æ¬¡ {current_batch} ç«‹å³é‡è¯•ä¸­ ({batch_retry_count + 1}/{max_batch_retries})...")
                            time.sleep(1)  # é‡è¯•å‰çŸ­æš‚ç­‰å¾…

                        batch_results = batch_download_chapters(item_ids, headers)
                        batch_retry_count += 1

                        if not batch_results and batch_retry_count < max_batch_retries and immediate_retry_enabled:
                            print(f"[Dlmityæ‰¹æ¬¡ {current_batch}] ç¬¬ {batch_retry_count} æ¬¡å°è¯•å¤±è´¥ï¼Œå°†ç«‹å³é‡è¯•")

                    if not batch_results:
                        if immediate_retry_enabled:
                            print(f"[Dlmityæ‰¹æ¬¡ {current_batch}] åœ¨ {batch_retry_count} æ¬¡ç«‹å³é‡è¯•åä»å¤±è´¥")
                            if self.status_callback:
                                self.status_callback(f"Dlmityç¬¬ {current_batch} æ‰¹åœ¨ {batch_retry_count} æ¬¡ç«‹å³é‡è¯•åä»å¤±è´¥ï¼Œå°†ä½¿ç”¨rabbits0209æ¨¡å¼é‡è¯•")
                        else:
                            print(f"[Dlmityæ‰¹æ¬¡ {current_batch}] ä¸‹è½½å¤±è´¥ï¼ˆç«‹å³é‡è¯•å·²ç¦ç”¨ï¼‰")
                            if self.status_callback:
                                self.status_callback(f"Dlmityç¬¬ {current_batch} æ‰¹ä¸‹è½½å¤±è´¥ï¼Œå°†ä½¿ç”¨rabbits0209æ¨¡å¼é‡è¯•")
                        failed_chapters.extend(batch)
                        continue

                    if batch_retry_count > 1 and immediate_retry_enabled:
                        print(f"[Dlmityæ‰¹æ¬¡ {current_batch}] æ€»å…±å°è¯•äº† {batch_retry_count} æ¬¡ï¼ŒæˆåŠŸï¼")

                    # å¤„ç†æ‰¹é‡ä¸‹è½½ç»“æœ
                    batch_success = 0
                    for chap in batch:
                        if self.stop_flag:
                            break

                        content = batch_results.get(chap["id"], "")
                        if isinstance(content, dict):
                            content = content.get("content", "")

                        if content:
                            processed = process_chapter_content(content)
                            with lock:
                                chapter_results[chap["index"]] = {
                                    "base_title": chap["title"],
                                    "api_title": "",
                                    "content": processed
                                }
                                downloaded.add(chap["id"])
                                batch_success += 1
                                batch_success_count += 1
                        else:
                            with lock:
                                failed_chapters.append(chap)

                    # æ‰¹æ¬¡å®Œæˆåæ›´æ–°è¿›åº¦ï¼ˆè€Œä¸æ˜¯åœ¨æ¯ä¸ªç« èŠ‚åï¼‰
                    current_downloaded = already_downloaded + batch_success_count
                    progress = int(current_downloaded / total_chapters * 100)
                    
                    # è°ƒè¯•ä¿¡æ¯
                    if self.status_callback:
                        self.status_callback(f"è¿›åº¦è°ƒè¯•: å·²ä¸‹è½½={already_downloaded}, æ‰¹æ¬¡æˆåŠŸ={batch_success_count}, æ€»ç« èŠ‚={total_chapters}, è¿›åº¦={progress}%")
                    
                    if self.progress_callback:
                        self.progress_callback(progress)

                    if self.status_callback:
                        self.status_callback(f"ç¬¬ {current_batch} æ‰¹å®Œæˆï¼ŒæˆåŠŸä¸‹è½½ {batch_success}/{len(batch)} ç« èŠ‚")

                # Dlmilyä¸‹è½½ç»“æœå·²å­˜å…¥chapter_results, æ— éœ€ç«‹å³å†™å…¥
                save_status(self.save_path, downloaded, self.book_id)
                todo_chapters = failed_chapters.copy()
                failed_chapters = []

                if self.status_callback and todo_chapters:
                    self.status_callback(f"Dlmilyä¸‹è½½å®Œæˆï¼Œå‰©ä½™ {len(todo_chapters)} ç« èŠ‚å°†ä½¿ç”¨rabbits0209æ¨¡å¼ä¸‹è½½")

            # rabbits0209ä¸‹è½½æ¨¡å¼ - ä½¿ç”¨qwqæ‰¹é‡è¯·æ±‚
            single_chapter_success_count = 0  # å•ç‹¬è®¡ç®—rabbits0209ä¸‹è½½çš„æˆåŠŸæ•°
            
            # åº”ç”¨rabbits0209ç« èŠ‚é™åˆ¶æ£€æŸ¥
            if todo_chapters and self.download_mode == 'single':
                try:
                    from config import CONFIG as user_config
                    is_over_limit, max_chapters, suggested_batches = check_rabbits0209_limit(todo_chapters, user_config)
                    
                    if is_over_limit:
                        if self.status_callback:
                            self.status_callback(f"æ£€æµ‹åˆ°ç« èŠ‚æ•°({len(todo_chapters)})è¶…è¿‡rabbits0209é™åˆ¶({max_chapters}ç« )")
                            self.status_callback(f"å°†è‡ªåŠ¨åˆ†ä¸º {suggested_batches} ä¸ªæ‰¹æ¬¡è¿›è¡Œä¸‹è½½")
                    else:
                        if self.status_callback:
                            self.status_callback(f"ç« èŠ‚æ•°({len(todo_chapters)})åœ¨é™åˆ¶èŒƒå›´å†…ï¼Œå¼€å§‹ä¸‹è½½")
                except Exception as e:
                    print(f"è­¦å‘Š: åº”ç”¨rabbits0209ç« èŠ‚é™åˆ¶æ—¶å‘ç”Ÿé”™è¯¯ {str(e)}")
            
            if self.status_callback and todo_chapters:
                self.status_callback("å¼€å§‹rabbits0209æ‰¹é‡è¯·æ±‚æ¨¡å¼...")

            # æ·»åŠ é‡è¯•å¾ªç¯æœºåˆ¶
            attempt = 1
            max_attempts = CONFIG.get("max_retries", 3)
            all_single_results = {}  # æ”¶é›†æ‰€æœ‰æˆåŠŸä¸‹è½½çš„ç« èŠ‚

            # è·å–rabbits0209æ¨¡å¼çš„æœ‰æ•ˆæ‰¹é‡å¤§å°ï¼ˆè€ƒè™‘ç« èŠ‚é™åˆ¶ï¼‰
            try:
                # ä½¿ç”¨å…¨å±€CONFIGï¼Œé¿å…é‡å¤å¯¼å…¥
                from config import CONFIG as user_config
                
                # è·å–ç”¨æˆ·é…ç½®çš„æ‰¹é‡å¤§å°
                user_batch_size = user_config.get("request", {}).get("single_batch_size", None)
                
                # è·å–ç« èŠ‚é™åˆ¶é…ç½®
                enable_limit = user_config.get("request", {}).get("rabbits0209_enable_limit", True)
                max_chapters = user_config.get("request", {}).get("rabbits0209_max_chapters", 30)
                
                if user_batch_size is not None:
                    # ç”¨æˆ·æ˜ç¡®é…ç½®äº†æ‰¹é‡å¤§å°ï¼Œrabbits0209 APIæœ€å¤§åªèƒ½æ¥å—30ç« 
                    configured_batch_size = min(user_batch_size, 30)  # æœ€å¤§é™åˆ¶30ç« 
                    print(f"ç”¨æˆ·é…ç½®çš„rabbits0209æ‰¹é‡å¤§å°: {configured_batch_size}")
                else:
                    # æœªé…ç½®æ—¶ï¼Œä½¿ç”¨çº¿ç¨‹æ•°ä½œä¸ºæ‰¹é‡å¤§å°ï¼ˆGUIå¯æ§åˆ¶ï¼‰
                    max_workers = CONFIG.get("max_workers", 4)
                    configured_batch_size = min(max_workers * 5, 30)  # çº¿ç¨‹æ•°çš„5å€ï¼Œæœ€å¤§30
                    print(f"æ ¹æ®çº¿ç¨‹æ•°({max_workers})è®¡ç®—rabbits0209æ‰¹é‡å¤§å°: {configured_batch_size}")
                
                # åº”ç”¨ç« èŠ‚é™åˆ¶
                if enable_limit and self.download_mode == 'single':
                    single_batch_size = min(configured_batch_size, max_chapters)
                    if single_batch_size != configured_batch_size:
                        print(f"åº”ç”¨rabbits0209ç« èŠ‚é™åˆ¶: æ‰¹é‡å¤§å°ä» {configured_batch_size} è°ƒæ•´ä¸º {single_batch_size}")
                        if self.status_callback:
                            self.status_callback(f"åº”ç”¨ç« èŠ‚é™åˆ¶: æ¯æ‰¹æœ€å¤š {single_batch_size} ç« èŠ‚")
                else:
                    single_batch_size = configured_batch_size
                    if self.status_callback and not enable_limit:
                        self.status_callback(f"æœªå¯ç”¨ç« èŠ‚é™åˆ¶ï¼Œä½¿ç”¨é…ç½®çš„æ‰¹é‡å¤§å°: {single_batch_size}")
                    
            except Exception as e:
                print(f"è·å–æ‰¹é‡å¤§å°é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼30")
                single_batch_size = 30

            # ç¡®ä¿æ‰¹é‡å¤§å°åœ¨åˆç†èŒƒå›´å†…ï¼ˆrabbits0209 APIé™åˆ¶ï¼‰
            if single_batch_size < 1:
                single_batch_size = 1
                print("æ‰¹é‡å¤§å°è°ƒæ•´ä¸ºæœ€å°å€¼1")
            elif single_batch_size > 30:
                single_batch_size = 30
                print("æ‰¹é‡å¤§å°è°ƒæ•´ä¸ºæœ€å¤§å€¼30ï¼ˆrabbits0209 APIé™åˆ¶ï¼‰")

            while todo_chapters and attempt <= max_attempts:
                if self.stop_flag:
                    break

                if attempt > 1 and self.status_callback:
                    self.status_callback(f"ç¬¬ {attempt} æ¬¡é‡è¯•ï¼Œå‰©ä½™ {len(todo_chapters)} ä¸ªç« èŠ‚...")

                failed_chapters_this_round = []

                # ä¿æŒå¤±è´¥ç« èŠ‚çš„å®Œæ•´ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ŒåŒ…æ‹¬åŸå§‹é¡ºåº
                chapter_context_map = {}
                for ch in todo_chapters:
                    chapter_context_map[ch["id"]] = {
                        "index": ch["index"],
                        "title": ch["title"],
                        "original_chapter": ch,
                        "retry_count": getattr(ch, 'retry_count', 0) + 1
                    }

                # ä½¿ç”¨rabbits0209æ‰¹é‡è¯·æ±‚
                if self.status_callback:
                    self.status_callback(f"ä½¿ç”¨rabbits0209æ‰¹é‡è¯·æ±‚ï¼Œæ¯æ‰¹ {single_batch_size} ç« èŠ‚...")
                
                # è®°å½•æ‰¹é‡ä¸‹è½½å¼€å§‹æ—¶é—´å’Œç»Ÿè®¡ä¿¡æ¯
                batch_start_time = time.time()
                total_batches_count = (len(todo_chapters) + single_batch_size - 1) // single_batch_size
                print(f"rabbits0209æ‰¹é‡ä¸‹è½½å¼€å§‹:")
                print(f"  - æ€»ç« èŠ‚æ•°: {len(todo_chapters)}")
                print(f"  - æ‰¹æ¬¡æ•°: {total_batches_count}")
                print(f"  - æ¯æ‰¹æœ€å¤š: {single_batch_size}ç« ")
                print(f"  - ç« èŠ‚é™åˆ¶: {'å¯ç”¨' if enable_limit else 'ç¦ç”¨'}")
                if enable_limit:
                    print(f"  - é™åˆ¶å€¼: {max_chapters}ç« ")
                    if configured_batch_size > max_chapters:
                        print(f"  - æ‰¹é‡å¤§å°å·²ä» {configured_batch_size} è°ƒæ•´ä¸º {single_batch_size}")
                print(f"  - å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S', time.localtime(batch_start_time))}")

                for batch_start in range(0, len(todo_chapters), single_batch_size):
                    if self.stop_flag:
                        break

                    batch_chapters = todo_chapters[batch_start:batch_start + single_batch_size]
                    # æŒ‰åŸå§‹ç´¢å¼•æ’åºï¼Œç¡®ä¿é¡ºåºæ­£ç¡®
                    batch_chapters = sorted(batch_chapters, key=lambda x: x["index"])
                    batch_item_ids = [ch["id"] for ch in batch_chapters]

                    batch_num = batch_start // single_batch_size + 1
                    total_batches = (len(todo_chapters) + single_batch_size - 1) // single_batch_size

                    # è®°å½•æ‰¹æ¬¡å¼€å§‹æ—¶é—´
                    batch_time_start = time.time()
                    
                    if self.status_callback:
                        self.status_callback(f"rabbits0209æ‰¹é‡è¯·æ±‚ç¬¬ {batch_num}/{total_batches} æ‰¹ ({len(batch_chapters)} ç« èŠ‚)")

                    print(f"[æ‰¹æ¬¡ {batch_num}] å¼€å§‹æ—¶é—´: {time.strftime('%H:%M:%S', time.localtime(batch_time_start))}")
                    print(f"[æ‰¹æ¬¡ {batch_num}] ç« èŠ‚ç´¢å¼•èŒƒå›´: {batch_chapters[0]['index']}-{batch_chapters[-1]['index']}")
                    print(f"[æ‰¹æ¬¡ {batch_num}] ç« èŠ‚IDs: {batch_item_ids[:3]}{'...' if len(batch_item_ids) > 3 else ''}")

                    # æ ¹æ®é…ç½®å†³å®šæ˜¯å¦ä½¿ç”¨ç«‹å³é‡è¯•æœºåˆ¶
                    immediate_retry_enabled = CONFIG.get("request", {}).get("immediate_retry", True)
                    batch_results = None
                    batch_retry_count = 0
                    max_batch_retries = CONFIG.get("request", {}).get("max_retries", 3) if immediate_retry_enabled else 1

                    while batch_retry_count < max_batch_retries and not batch_results:
                        if batch_retry_count > 0 and immediate_retry_enabled:
                            print(f"[æ‰¹æ¬¡ {batch_num}] ç¬¬ {batch_retry_count + 1} æ¬¡å°è¯•...")
                            if self.status_callback:
                                self.status_callback(f"æ‰¹æ¬¡ {batch_num} ç«‹å³é‡è¯•ä¸­ ({batch_retry_count + 1}/{max_batch_retries})...")
                            time.sleep(1)  # é‡è¯•å‰çŸ­æš‚ç­‰å¾…

                        batch_results = qwq_batch_download_chapters(batch_item_ids, headers)
                        batch_retry_count += 1

                        if not batch_results and batch_retry_count < max_batch_retries and immediate_retry_enabled:
                            print(f"[æ‰¹æ¬¡ {batch_num}] ç¬¬ {batch_retry_count} æ¬¡å°è¯•å¤±è´¥ï¼Œå°†ç«‹å³é‡è¯•")

                    # è®°å½•æ‰¹æ¬¡ç»“æŸæ—¶é—´
                    batch_time_end = time.time()
                    batch_duration = batch_time_end - batch_time_start
                    print(f"[æ‰¹æ¬¡ {batch_num}] ç»“æŸæ—¶é—´: {time.strftime('%H:%M:%S', time.localtime(batch_time_end))}")
                    print(f"[æ‰¹æ¬¡ {batch_num}] è€—æ—¶: {batch_duration:.2f}ç§’")

                    if batch_retry_count > 1 and immediate_retry_enabled:
                        print(f"[æ‰¹æ¬¡ {batch_num}] æ€»å…±å°è¯•äº† {batch_retry_count} æ¬¡")
                    elif not immediate_retry_enabled:
                        print(f"[æ‰¹æ¬¡ {batch_num}] ç«‹å³é‡è¯•å·²ç¦ç”¨ï¼Œå¤±è´¥æ‰¹æ¬¡å°†åœ¨æœ€åç»Ÿä¸€é‡è¯•")

                    if batch_results:
                        # ä¸¥æ ¼æŒ‰ç…§è¯·æ±‚é¡ºåºå¤„ç†æ‰¹é‡ä¸‹è½½ç»“æœï¼Œä½¿ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯éªŒè¯
                        successful_in_batch = 0
                        print(f"[æ‰¹æ¬¡ {batch_num}] å¤„ç†ä¸‹è½½ç»“æœ: æ”¶åˆ° {len(batch_results)} ä¸ªç« èŠ‚æ•°æ®")
                        
                        for chapter in batch_chapters:
                            chapter_id = chapter["id"]
                            if chapter_id in batch_results:
                                chapter_data = batch_results[chapter_id]
                                content = chapter_data.get("content", "")
                                title = chapter_data.get("title", "")

                                # éªŒè¯ç« èŠ‚ä¸Šä¸‹æ–‡ä¿¡æ¯
                                if chapter_id in chapter_context_map:
                                    expected_index = chapter_context_map[chapter_id]["index"]
                                    expected_title = chapter_context_map[chapter_id]["title"]

                                    # éªŒè¯ç´¢å¼•ä¸€è‡´æ€§
                                    if chapter["index"] != expected_index:
                                        print(f"è­¦å‘Šï¼šç« èŠ‚ {chapter_id} ç´¢å¼•ä¸ä¸€è‡´ï¼ŒæœŸæœ› {expected_index}ï¼Œå®é™… {chapter['index']}")

                                    # å¯é€‰ï¼šéªŒè¯æ ‡é¢˜ç›¸ä¼¼æ€§ï¼ˆç®€å•æ£€æŸ¥ï¼‰
                                    if title and expected_title and title not in expected_title and expected_title not in title:
                                        print(f"è­¦å‘Šï¼šç« èŠ‚ {chapter_id} æ ‡é¢˜å¯èƒ½ä¸åŒ¹é…ï¼ŒæœŸæœ›åŒ…å« '{expected_title}'ï¼Œå®é™… '{title}'")

                                if content:
                                    # ä½¿ç”¨ç« èŠ‚çš„åŸå§‹ç´¢å¼•ç¡®ä¿æ­£ç¡®é¡ºåºï¼Œå¹¶è®°å½•ä¸Šä¸‹æ–‡ä¿¡æ¯
                                    if chapter_id in chapter_context_map:
                                        original_index = chapter_context_map[chapter_id]["index"]
                                        original_chapter = chapter_context_map[chapter_id]["original_chapter"]
                                        retry_count = chapter_context_map[chapter_id]["retry_count"]

                                        all_single_results[original_index] = (original_chapter, title, content)
                                        print(f"æ‰¹é‡ä¸‹è½½æˆåŠŸï¼šç¬¬{original_index+1}ç«  {chapter['title']} (é‡è¯•{retry_count}æ¬¡)")
                                    else:
                                        all_single_results[chapter["index"]] = (chapter, title, content)
                                        print(f"æ‰¹é‡ä¸‹è½½æˆåŠŸï¼šç¬¬{chapter['index']+1}ç«  {chapter['title']}")

                                    downloaded.add(chapter["id"])
                                    save_status(self.save_path, downloaded, self.book_id)
                                    single_chapter_success_count += 1
                                    successful_in_batch += 1

                                    if self.status_callback:
                                        current_pos = already_downloaded + batch_success_count + single_chapter_success_count
                                        self.status_callback(f"å·²ä¸‹è½½: {title or chapter['title']} ({current_pos}/{total_chapters})")
                                    if self.progress_callback:
                                        progress = int(current_pos / total_chapters * 100)
                                        self.progress_callback(progress)
                                else:
                                    # ä¿ç•™å®Œæ•´ä¸Šä¸‹æ–‡ä¿¡æ¯ç”¨äºé‡è¯•
                                    if chapter_id in chapter_context_map:
                                        failed_chapter = chapter_context_map[chapter_id]["original_chapter"].copy()
                                        failed_chapter['retry_count'] = chapter_context_map[chapter_id]['retry_count']
                                        failed_chapters_this_round.append(failed_chapter)
                                    else:
                                        failed_chapters_this_round.append(chapter)
                                    print(f"ç« èŠ‚ {chapter_id} (ç¬¬{chapter['index']+1}ç« : {chapter['title']}) å†…å®¹ä¸ºç©º")
                            else:
                                # æ‰¹é‡ç»“æœä¸­æ²¡æœ‰è¿™ä¸ªç« èŠ‚ï¼Œä¿æŒåŸå§‹é¡ºåºä¿¡æ¯å¹¶æ ‡è®°ä¸ºå¤±è´¥
                                if chapter_id in chapter_context_map:
                                    failed_chapter = chapter_context_map[chapter_id]["original_chapter"].copy()
                                    failed_chapter['retry_count'] = chapter_context_map[chapter_id]['retry_count']
                                    failed_chapters_this_round.append(failed_chapter)
                                else:
                                    failed_chapters_this_round.append(chapter)
                                print(f"ç« èŠ‚ {chapter_id} (ç¬¬{chapter['index']+1}ç« : {chapter['title']}) ä¸åœ¨æ‰¹é‡ç»“æœä¸­")

                        # è®°å½•æ‰¹æ¬¡å®Œæˆç»Ÿè®¡
                        print(f"[æ‰¹æ¬¡ {batch_num}] å®Œæˆç»Ÿè®¡: æˆåŠŸ={successful_in_batch}/{len(batch_chapters)}, å¤±è´¥={len(batch_chapters)-successful_in_batch}")
                        print(f"[æ‰¹æ¬¡ {batch_num}] æˆåŠŸç‡: {successful_in_batch/len(batch_chapters)*100:.1f}%")
                        
                        if self.status_callback:
                            self.status_callback(f"ç¬¬ {batch_num} æ‰¹å®Œæˆ: {successful_in_batch}/{len(batch_chapters)} ç« èŠ‚æˆåŠŸ")
                    else:
                        # æ•´æ‰¹å¤±è´¥ï¼Œä¿æŒç« èŠ‚é¡ºåºä¿¡æ¯å¹¶åŠ å…¥é‡è¯•åˆ—è¡¨
                        print(f"[æ‰¹æ¬¡ {batch_num}] å®Œå…¨å¤±è´¥ï¼Œç« èŠ‚ç´¢å¼•: {[ch['index'] for ch in batch_chapters]}")
                        if immediate_retry_enabled:
                            print(f"[æ‰¹æ¬¡ {batch_num}] å¤±è´¥åŸå› : æ‰¹é‡è¯·æ±‚åœ¨ {batch_retry_count} æ¬¡ç«‹å³é‡è¯•åä»è¿”å›ç©ºç»“æœ")
                            if self.status_callback:
                                self.status_callback(f"ç¬¬ {batch_num} æ‰¹åœ¨ {batch_retry_count} æ¬¡ç«‹å³é‡è¯•åä»å¤±è´¥ï¼Œå°†åœ¨ä¸‹è½®é‡è¯•")
                        else:
                            print(f"[æ‰¹æ¬¡ {batch_num}] å¤±è´¥åŸå› : æ‰¹é‡è¯·æ±‚è¿”å›ç©ºç»“æœï¼ˆç«‹å³é‡è¯•å·²ç¦ç”¨ï¼‰")
                            if self.status_callback:
                                self.status_callback(f"ç¬¬ {batch_num} æ‰¹å¤±è´¥ï¼Œå°†åœ¨æœ€åç»Ÿä¸€é‡è¯•")
                        failed_chapters_this_round.extend(batch_chapters)

                    # æ‰¹æ¬¡é—´å»¶è¿Ÿ
                    time.sleep(CONFIG["request_rate_limit"])



                # æ›´æ–°å¾…é‡è¯•ç« èŠ‚åˆ—è¡¨ - æŒ‰åŸå§‹ç´¢å¼•æ’åºä¿æŒé¡ºåº
                todo_chapters = sorted(failed_chapters_this_round.copy(), key=lambda x: x["index"])
                
                if todo_chapters:
                    print(f"æœ¬è½®é‡è¯•å¤±è´¥ç« èŠ‚ç´¢å¼•: {[ch['index'] for ch in todo_chapters]}")
                    if self.status_callback:
                        index_ranges = f"ç¬¬{todo_chapters[0]['index']+1}ç« " + (f"-ç¬¬{todo_chapters[-1]['index']+1}ç« " if len(todo_chapters) > 1 else "")
                        self.status_callback(f"æœ¬è½®å‰©ä½™å¤±è´¥ç« èŠ‚: {len(todo_chapters)}ä¸ª ({index_ranges})")
                
                attempt += 1

                # å¦‚æœè¿˜æœ‰å¤±è´¥ç« èŠ‚ä¸”æœªè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œç­‰å¾…åé‡è¯•
                if todo_chapters and attempt <= max_attempts:
                    if self.status_callback:
                        self.status_callback(f"ç­‰å¾… 2 ç§’åè¿›è¡Œç¬¬ {attempt} æ¬¡é‡è¯•...")
                    time.sleep(2)
            
            # è®°å½•rabbits0209ä¸‹è½½å®Œæˆç»Ÿè®¡
            batch_end_time = time.time()
            total_batch_duration = batch_end_time - batch_start_time
            print(f"rabbits0209æ‰¹é‡ä¸‹è½½å®Œæˆç»Ÿè®¡:")
            print(f"  - æ€»è€—æ—¶: {total_batch_duration:.2f}ç§’")
            print(f"  - æ€»æ‰¹æ¬¡æ•°: {total_batches_count}")
            print(f"  - æ¯æ‰¹æœ€å¤§ç« èŠ‚æ•°: {single_batch_size}")
            print(f"  - ç« èŠ‚é™åˆ¶çŠ¶æ€: {'å·²å¯ç”¨' if enable_limit else 'æœªå¯ç”¨'}")
            if enable_limit:
                print(f"  - ç« èŠ‚é™åˆ¶å€¼: {max_chapters}ç« ")
            print(f"  - æˆåŠŸç« èŠ‚æ•°: {single_chapter_success_count}")
            print(f"  - å¤±è´¥ç« èŠ‚æ•°: {len(todo_chapters)}")
            print(f"  - æˆåŠŸç‡: {single_chapter_success_count/(single_chapter_success_count+len(todo_chapters))*100:.1f}%" if (single_chapter_success_count+len(todo_chapters)) > 0 else "  - æˆåŠŸç‡: 0%")
            
            if self.status_callback:
                if len(todo_chapters) == 0:
                    self.status_callback(f"rabbits0209ä¸‹è½½å®Œæˆ: å…¨éƒ¨ {single_chapter_success_count} ç« èŠ‚ä¸‹è½½æˆåŠŸ")
                else:
                    self.status_callback(f"rabbits0209ä¸‹è½½å®Œæˆ: {single_chapter_success_count} ç« èŠ‚æˆåŠŸï¼Œ{len(todo_chapters)} ç« èŠ‚å¤±è´¥")
            # ç»Ÿä¸€å†™å…¥é€»è¾‘ï¼šåœ¨æ‰€æœ‰ä¸‹è½½å°è¯•ç»“æŸåï¼Œå¯¹æ‰€æœ‰æˆåŠŸä¸‹è½½çš„ç« èŠ‚è¿›è¡Œæ’åºå’Œå†™å…¥
            if self.status_callback:
                self.status_callback("æ‰€æœ‰ä¸‹è½½å°è¯•å·²å®Œæˆï¼Œå¼€å§‹æ•´åˆå’Œå†™å…¥æœ€ç»ˆæ–‡ä»¶...")

            # 1. å°† rabbits0209 ä¸‹è½½çš„æ‰€æœ‰æˆåŠŸç»“æœåˆå¹¶åˆ°ä¸»ç« èŠ‚ç»“æœå­—å…¸ä¸­
            if all_single_results:
                for idx, (chapter, title, content) in all_single_results.items():
                    # ç¡®ä¿å³ä½¿åœ¨é‡è¯•åï¼Œç»“æœä¹Ÿè¢«æ­£ç¡®åœ°æ”¾å…¥ä¸»å®¹å™¨
                    if idx not in chapter_results:
                        chapter_results[idx] = {
                            "base_title": chapter["title"],
                            "api_title": title,
                            "content": content
                        }

            # 2. åªæœ‰åœ¨è‡³å°‘ä¸‹è½½äº†ä¸€ä¸ªç« èŠ‚çš„æƒ…å†µä¸‹æ‰æ‰§è¡Œå†™å…¥
            if chapter_results:
                # å¯¹æ‰€æœ‰æ”¶é›†åˆ°çš„ç»“æœè¿›è¡Œæœ€ç»ˆçš„å®Œæ•´æ€§æ£€æŸ¥
                is_valid, issues = validate_chapter_integrity(chapter_results, len(chapters), chapters)
                if not is_valid:
                    if self.status_callback:
                        self.status_callback(f"è­¦å‘Šï¼šæ£€æµ‹åˆ° {len(issues)} ä¸ªç« èŠ‚å®Œæ•´æ€§é—®é¢˜ã€‚")
                    for issue in issues:
                        print(f"  - {issue}")
                else:
                    if self.status_callback:
                        self.status_callback("ç« èŠ‚å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡ã€‚")

                # 3. æ ¸å¿ƒä¿®å¤ï¼šå§‹ç»ˆä½¿ç”¨è¦†ç›–æ¨¡å¼('w')é‡å†™æ•´ä¸ªæ–‡ä»¶ï¼Œä»¥ç¡®ä¿æœ€ç»ˆé¡ºåºç»å¯¹æ­£ç¡®
                try:
                    with open(output_file_path, 'w', encoding='utf-8') as f:
                        f.write(self._generate_book_header(name, author_name, description, enhanced_info))

                        if not is_valid:
                            f.write("=" * 50 + "\n")
                            f.write("è­¦å‘Šï¼šæœ¬ä¹¦ç±æ–‡ä»¶å¯èƒ½å­˜åœ¨ä»¥ä¸‹å®Œæ•´æ€§é—®é¢˜ï¼š\n")
                            for issue in issues:
                                f.write(f"- {issue}\n")
                            f.write("=" * 50 + "\n\n")

                        # ä¸¥æ ¼æŒ‰ç…§ç« èŠ‚çš„åŸå§‹ç´¢å¼•æ’åºå¹¶å†™å…¥
                        written_count = 0
                        sorted_indices = sorted(chapter_results.keys())
                        for idx in sorted_indices:
                            result = chapter_results[idx]
                            # ä¼˜å…ˆä½¿ç”¨APIè¿”å›çš„æ ‡é¢˜ï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨æˆ‘ä»¬è‡ªå·±ç”Ÿæˆçš„æ ‡é¢˜
                            title_display = result["api_title"] or result["base_title"]
                            f.write(f"{title_display}\n{result['content']}\n\n")
                            written_count += 1
                    
                    if self.status_callback:
                        range_text = f"ç¬¬{sorted_indices[0]+1}-{sorted_indices[-1]+1}ç« " if sorted_indices else "æ— "
                        self.status_callback(f"æ–‡ä»¶å†™å…¥æˆåŠŸ: å…±å†™å…¥ {written_count} ä¸ªç« èŠ‚ (èŒƒå›´: {range_text})")

                    # ğŸ”§ åº”ç”¨ä¸‹è½½åç« èŠ‚çŸ«æ­£
                    try:
                        if self.status_callback:
                            self.status_callback("æ­£åœ¨è¿›è¡Œä¸‹è½½åç« èŠ‚çŸ«æ­£æ£€æŸ¥...")
                        
                        # å‡†å¤‡å·²ä¸‹è½½ç« èŠ‚æ•°æ®ç”¨äºçŸ«æ­£
                        downloaded_chapters_for_correction = []
                        for idx in sorted_indices:
                            result = chapter_results[idx]
                            downloaded_chapters_for_correction.append({
                                "id": str(idx),
                                "title": result["api_title"] or result["base_title"],
                                "content": result["content"],
                                "index": idx
                            })
                        
                        # æ‰§è¡Œä¸‹è½½åçŸ«æ­£
                        corrected_chapters, correction_report = apply_post_download_correction(
                            downloaded_chapters_for_correction, 
                            enhanced_info
                        )
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰çŸ«æ­£å˜åŒ–
                        original_titles = [ch["title"] for ch in downloaded_chapters_for_correction]
                        corrected_titles = [ch["title"] for ch in corrected_chapters]
                        
                        if original_titles != corrected_titles:
                            # æœ‰çŸ«æ­£å˜åŒ–ï¼Œé‡æ–°å†™å…¥æ–‡ä»¶
                            if self.status_callback:
                                self.status_callback("æ£€æµ‹åˆ°ç« èŠ‚é¡ºåºéœ€è¦ä¼˜åŒ–ï¼Œæ­£åœ¨é‡æ–°ç”Ÿæˆæ–‡ä»¶...")
                            
                            with open(output_file_path, 'w', encoding='utf-8') as f:
                                f.write(self._generate_book_header(name, author_name, description, enhanced_info))
                                
                                # å†™å…¥çŸ«æ­£æŠ¥å‘Š
                                f.write("=" * 50 + "\n")
                                f.write("ğŸ“š ç« èŠ‚çŸ«æ­£ä¿¡æ¯\n")
                                f.write("=" * 50 + "\n")
                                f.write(correction_report + "\n\n")
                                
                                # æŒ‰çŸ«æ­£åçš„é¡ºåºå†™å…¥ç« èŠ‚
                                for chapter in corrected_chapters:
                                    f.write(f"{chapter['title']}\n{chapter['content']}\n\n")
                            
                            if self.status_callback:
                                self.status_callback("âœ… ç« èŠ‚çŸ«æ­£å®Œæˆï¼Œæ–‡ä»¶å·²æŒ‰æœ€ä¼˜é¡ºåºé‡æ–°ç”Ÿæˆ")
                        else:
                            if self.status_callback:
                                self.status_callback("â„¹ï¸ ç« èŠ‚é¡ºåºå·²æ˜¯æœ€ä¼˜ï¼Œæ— éœ€è°ƒæ•´")
                        
                        # åœ¨GUIä¸­æ˜¾ç¤ºçŸ«æ­£æŠ¥å‘Šæ‘˜è¦
                        if self.status_callback and correction_report:
                            # æå–å…³é”®ä¿¡æ¯æ˜¾ç¤º
                            if "ç« èŠ‚é¡ºåºå·²é‡æ–°ä¼˜åŒ–" in correction_report:
                                self.status_callback("ğŸ“‹ çŸ«æ­£æ‘˜è¦: ç« èŠ‚é¡ºåºå·²ä¼˜åŒ–")
                            elif "å¤„ç†çš„é—®é¢˜" in correction_report:
                                self.status_callback("ğŸ“‹ çŸ«æ­£æ‘˜è¦: å‘ç°å¹¶å¤„ç†äº†ç« èŠ‚é—®é¢˜")
                            else:
                                self.status_callback("ğŸ“‹ çŸ«æ­£æ‘˜è¦: ç« èŠ‚æ£€æŸ¥å®Œæˆ")
                                
                    except Exception as correction_error:
                        print(f"ä¸‹è½½åç« èŠ‚çŸ«æ­£å¤±è´¥: {str(correction_error)}")
                        if self.status_callback:
                            self.status_callback(f"ç« èŠ‚çŸ«æ­£è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜: {str(correction_error)}")

                except Exception as e:
                    error_msg = f"é”™è¯¯: æœ€ç»ˆæ–‡ä»¶å†™å…¥å¤±è´¥: {str(e)}"
                    if self.status_callback: self.status_callback(error_msg)
                    print(error_msg)
            else:
                if self.status_callback:
                    self.status_callback("æ²¡æœ‰ä»»ä½•æˆåŠŸä¸‹è½½çš„ç« èŠ‚ï¼Œæ— éœ€å†™å…¥æ–‡ä»¶ã€‚")

            # æŠ¥å‘Šæœ€ç»ˆå¤±è´¥çš„ç« èŠ‚ï¼ˆæŒ‰ç« èŠ‚é¡ºåºï¼‰
            if todo_chapters and self.status_callback:
                failed_chapter_numbers = [ch['index'] + 1 for ch in sorted(todo_chapters, key=lambda x: x['index'])]
                failed_ranges = []
                start = failed_chapter_numbers[0]
                end = failed_chapter_numbers[0]
                
                # å°†è¿ç»­ç« èŠ‚åˆå¹¶ä¸ºèŒƒå›´æ˜¾ç¤º
                for i in range(1, len(failed_chapter_numbers)):
                    if failed_chapter_numbers[i] == end + 1:
                        end = failed_chapter_numbers[i]
                    else:
                        if start == end:
                            failed_ranges.append(f"ç¬¬{start}ç« ")
                        else:
                            failed_ranges.append(f"ç¬¬{start}-{end}ç« ")
                        start = end = failed_chapter_numbers[i]
                
                # æ·»åŠ æœ€åä¸€ä¸ªèŒƒå›´
                if start == end:
                    failed_ranges.append(f"ç¬¬{start}ç« ")
                else:
                    failed_ranges.append(f"ç¬¬{start}-{end}ç« ")
                
                self.status_callback(f"è­¦å‘Šï¼š{len(todo_chapters)}ä¸ªç« èŠ‚åœ¨{max_attempts}æ¬¡é‡è¯•åä»ç„¶å¤±è´¥: {', '.join(failed_ranges)}")

            # è®¡ç®—æ€»æˆåŠŸæ•°å’Œæœ€ç»ˆç»Ÿè®¡
            total_success_count = batch_success_count + single_chapter_success_count
            final_progress = int((already_downloaded + total_success_count) / total_chapters * 100)
            
            # æœ€ç»ˆéªŒè¯å’Œç»Ÿè®¡
            if self.status_callback:
                success_rate = (total_success_count / len(todo_chapters) * 100) if todo_chapters else 100
                self.status_callback(f"ä¸‹è½½å®Œæˆï¼æœ¬æ¬¡æˆåŠŸ {total_success_count}/{len(chapters)-already_downloaded} ç« èŠ‚ (æˆåŠŸç‡: {success_rate:.1f}%)")
                self.status_callback(f"æ€»è¿›åº¦: {already_downloaded + total_success_count}/{total_chapters} ç« èŠ‚ ({final_progress}%)")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç”ŸæˆEPUB
            if self.output_format == "EPUB" or (self.output_format == "TXT" and self.generate_epub_when_txt):
                try:
                    from utils import generate_enhanced_epub, generate_epub, sanitize_filename, EBOOKLIB_AVAILABLE
                    
                    if not EBOOKLIB_AVAILABLE:
                        if self.status_callback:
                            self.status_callback("è­¦å‘Šï¼šebooklibæœªå®‰è£…ï¼Œæ— æ³•ç”ŸæˆEPUBæ–‡ä»¶")
                    else:
                        if self.status_callback:
                            self.status_callback("æ­£åœ¨ç”Ÿæˆå¢å¼ºç‰ˆEPUBæ–‡ä»¶...")
                            
                        # æ¸…ç†æ–‡ä»¶å
                        safe_name = sanitize_filename(name)
                        txt_file_path = os.path.join(self.save_path, f"{safe_name}.txt")
                        
                        if os.path.exists(txt_file_path):
                            # ä¼˜å…ˆä½¿ç”¨å¢å¼ºç‰ˆEPUBç”Ÿæˆï¼ˆåŒ…å«è¯¦ç»†ä¿¡æ¯å’Œå°é¢ï¼‰
                            if enhanced_info:
                                success = generate_enhanced_epub(
                                    txt_file_path=txt_file_path,
                                    output_dir=self.save_path,
                                    book_info=enhanced_info
                                )
                            else:
                                # å›é€€åˆ°åŸºç¡€EPUBç”Ÿæˆ
                                success = generate_epub(
                                    txt_file_path=txt_file_path,
                                    output_dir=self.save_path,
                                    book_title=safe_name,
                                    author=author_name,
                                    description=description
                                )
                            
                            if success:
                                if self.status_callback:
                                    epub_type = "å¢å¼ºç‰ˆEPUB" if enhanced_info else "åŸºç¡€EPUB"
                                    self.status_callback(f"{epub_type}æ–‡ä»¶ç”ŸæˆæˆåŠŸï¼")
                            else:
                                if self.status_callback:
                                    self.status_callback("EPUBæ–‡ä»¶ç”Ÿæˆå¤±è´¥")
                        else:
                            if self.status_callback:
                                self.status_callback("è­¦å‘Šï¼šæ‰¾ä¸åˆ°TXTæ–‡ä»¶ï¼Œæ— æ³•ç”ŸæˆEPUB")
                                
                except ImportError:
                    if self.status_callback:
                        self.status_callback("é”™è¯¯ï¼šæ— æ³•å¯¼å…¥epubç”Ÿæˆæ¨¡å—")
                except Exception as e:
                    if self.status_callback:
                        self.status_callback(f"EPUBç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")

            if self.progress_callback:
                self.progress_callback(final_progress)

        except Exception as e:
            if self.status_callback:
                self.status_callback(f"ä¸‹è½½è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            print(f"ä¸‹è½½å¼‚å¸¸è¯¦æƒ…: {str(e)}")
            import traceback
            traceback.print_exc()

def main():
    print("""æ¬¢è¿ä½¿ç”¨ç•ªèŒ„å°è¯´ä¸‹è½½å™¨ç²¾ç®€ç‰ˆï¼
å¼€å‘è€…ï¼šDlmily
å½“å‰ç‰ˆæœ¬ï¼šv1.7
Githubï¼šhttps://github.com/Dlmily/Tomato-Novel-Downloader-Lite
èµåŠ©/äº†è§£æ–°äº§å“ï¼šhttps://afdian.com/a/dlbaokanluntanos
*ä½¿ç”¨å‰é¡»çŸ¥*ï¼š
    1.å¼€å§‹ä¸‹è½½ä¹‹åï¼Œæ‚¨å¯èƒ½ä¼šè¿‡äºç€æ€¥è€ŒæŸ¥çœ‹ä¸‹è½½æ–‡ä»¶çš„ä½ç½®ï¼Œè¿™æ˜¯å¾’åŠ³çš„ï¼Œè¯·è€å¿ƒç­‰å¾…å°è¯´ä¸‹è½½å®Œæˆå†æŸ¥çœ‹ï¼å¦å¤–å¦‚æœä½ è¦ä¸‹è½½ä¹‹å‰å·²ç»ä¸‹è½½è¿‡çš„å°è¯´(åœ¨æ­¤ä¹‹å‰å·²ç»åˆ é™¤äº†åŸtxtæ–‡ä»¶)ï¼Œé‚£ä¹ˆä½ æœ‰å¯èƒ½ä¼šé‡åˆ°"æ‰€æœ‰ç« èŠ‚å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€ä¸‹è½½"çš„æƒ…å†µï¼Œè¿™æ—¶å°±è¯·åˆ é™¤æ‰chapter.jsonï¼Œç„¶åå†æ¬¡è¿è¡Œç¨‹åºã€‚
    2.æ‚¨å¯ä»¥è‡ªè¡Œé€‰æ‹©ä½¿ç”¨Torç½‘ç»œè¿›è¡Œä¸‹è½½ï¼ŒTorç½‘ç»œèƒ½å¤Ÿå¾ˆå¥½åœ°é˜²æ­¢Apiå¼€å‘è€…å°ipã€‚

å¦ï¼šå¦‚æœæœ‰å¸¦ç•ªèŒ„svipçš„cookieæˆ–apiï¼ŒæŒ‰ç…§æ‚¨çš„æ„æ„¿æŠ•åˆ°"Issues"é¡µä¸­ã€‚
------------------------------------------""")
    use_tor = input("æ˜¯å¦è¦ä½¿ç”¨Torç½‘ç»œè¿›è¡Œä¸‹è½½ï¼Ÿ(y/n, é»˜è®¤ä¸ºn): ").strip().lower()
    if use_tor == 'y':
        if not enable_tor_support():
            print("å°†ä¸ä½¿ç”¨Torç½‘ç»œç»§ç»­è¿è¡Œ")

    print("æ­£åœ¨ä»æœåŠ¡å™¨è·å–APIåˆ—è¡¨...")
    fetch_api_endpoints_from_server()

    while True:
        book_id = input("è¯·è¾“å…¥å°è¯´IDï¼ˆè¾“å…¥qé€€å‡ºï¼‰ï¼š").strip()
        if book_id.lower() == 'q':
            break

        save_path = input("ä¿å­˜è·¯å¾„ï¼ˆç•™ç©ºä¸ºå½“å‰ç›®å½•ï¼‰ï¼š").strip() or os.getcwd()

        try:
            Run(book_id, save_path)
        except Exception as e:
            print(f"è¿è¡Œé”™è¯¯: {str(e)}")

        print("\n" + "="*50 + "\n")

if __name__ == "__main__":
    main()
